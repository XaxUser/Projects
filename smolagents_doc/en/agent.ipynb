{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/ky2o5sgiFwxbXMK+zOFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7520f61d1ad542c6a708fe971c834ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaea33eb51584faf82f597eea55c6f61",
              "IPY_MODEL_324abedc8c1f41c88fe502640c9a66e8",
              "IPY_MODEL_b0b911caf03346db999c3a6ec0d219fa"
            ],
            "layout": "IPY_MODEL_cb540107445446edb370a66d33ea93df"
          }
        },
        "eaea33eb51584faf82f597eea55c6f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ddb2cc7599846ba93bac0da24b78864",
            "placeholder": "​",
            "style": "IPY_MODEL_a65db16d37044da8add2f0e7880f38dd",
            "value": "Fetching 5 files: 100%"
          }
        },
        "324abedc8c1f41c88fe502640c9a66e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566678c2933f4eac9c085fd134528a49",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76e2161089a247d887b87a6b52c82158",
            "value": 5
          }
        },
        "b0b911caf03346db999c3a6ec0d219fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_098c15235a1b4c6b8d55dc32c44dc59a",
            "placeholder": "​",
            "style": "IPY_MODEL_fc269046964b4e619fa46b713f7dcd2e",
            "value": " 5/5 [00:01&lt;00:00,  1.22it/s]"
          }
        },
        "cb540107445446edb370a66d33ea93df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ddb2cc7599846ba93bac0da24b78864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a65db16d37044da8add2f0e7880f38dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566678c2933f4eac9c085fd134528a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e2161089a247d887b87a6b52c82158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "098c15235a1b4c6b8d55dc32c44dc59a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc269046964b4e619fa46b713f7dcd2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d315cc8b188400b96af5381f80bac99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08a855d6b63c46e3a2c60307d72ae6e1",
              "IPY_MODEL_81c515f9e6c14aedb4d130b6ce0a39dd",
              "IPY_MODEL_1e22339990e747c4816d6e35e0e9e077"
            ],
            "layout": "IPY_MODEL_37c629faf44e4ae485062dee8a1cc385"
          }
        },
        "08a855d6b63c46e3a2c60307d72ae6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_308baafd6eaa49098aacd0439d750e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_27f437013b6b446987c7c3a813a14d93",
            "value": "model_optimized.onnx: 100%"
          }
        },
        "81c515f9e6c14aedb4d130b6ce0a39dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b15000898cee41f5baae82c136b89796",
            "max": 66465124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe92f316fd3649989b5fb7f9f02e56cc",
            "value": 66465124
          }
        },
        "1e22339990e747c4816d6e35e0e9e077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ac163c21546470ab9308727190304d5",
            "placeholder": "​",
            "style": "IPY_MODEL_26c8e32bc79d4e4a8562b3b9fba7b4e0",
            "value": " 66.5M/66.5M [00:01&lt;00:00, 77.4MB/s]"
          }
        },
        "37c629faf44e4ae485062dee8a1cc385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308baafd6eaa49098aacd0439d750e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f437013b6b446987c7c3a813a14d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b15000898cee41f5baae82c136b89796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe92f316fd3649989b5fb7f9f02e56cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ac163c21546470ab9308727190304d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c8e32bc79d4e4a8562b3b9fba7b4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce4f289b558e4757ae264e1ce3fa42bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eb32830f7854d2198f4183d7c887827",
              "IPY_MODEL_8d2933004c284aeaad958d53013bde0e",
              "IPY_MODEL_4669c4b660a047e8ac3a97988b202187"
            ],
            "layout": "IPY_MODEL_30badb34cdc0484c8122c77141d47920"
          }
        },
        "4eb32830f7854d2198f4183d7c887827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adfa6966d86748b1a33e535e05c4a278",
            "placeholder": "​",
            "style": "IPY_MODEL_175fefb5ac09499d8d6f348716faa634",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8d2933004c284aeaad958d53013bde0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04a0956e9a64ffb837d533e78806718",
            "max": 1242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ee1103753804c70a0f05f375766abc3",
            "value": 1242
          }
        },
        "4669c4b660a047e8ac3a97988b202187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e152b19cb1041cdbc00dfd74bfa5441",
            "placeholder": "​",
            "style": "IPY_MODEL_7f60c61967eb4c5f8abf155b20137c73",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "30badb34cdc0484c8122c77141d47920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adfa6966d86748b1a33e535e05c4a278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175fefb5ac09499d8d6f348716faa634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a04a0956e9a64ffb837d533e78806718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee1103753804c70a0f05f375766abc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e152b19cb1041cdbc00dfd74bfa5441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f60c61967eb4c5f8abf155b20137c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a740a6abe9e45afbe27a1072b9521d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a39e3d554db4e1c988d52aaa0c9a870",
              "IPY_MODEL_51d870df56cd4fab8298e30268ea1513",
              "IPY_MODEL_1b9d5754c89f432caac8971adc5476e7"
            ],
            "layout": "IPY_MODEL_f430daf9df30461ca939404ffac3875b"
          }
        },
        "9a39e3d554db4e1c988d52aaa0c9a870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2478f7267eb4f1a86bd816d1fdab481",
            "placeholder": "​",
            "style": "IPY_MODEL_a5f18b8001b74c0e8182be129836724e",
            "value": "config.json: 100%"
          }
        },
        "51d870df56cd4fab8298e30268ea1513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb77f9351764919b456cb93188a2a3d",
            "max": 706,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_723b75c6746947ccbf11c5190e4dd616",
            "value": 706
          }
        },
        "1b9d5754c89f432caac8971adc5476e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03de5ccd15e845228a9b2f3b98596468",
            "placeholder": "​",
            "style": "IPY_MODEL_9285b8b1c8a94520b4b5bbc9b4306975",
            "value": " 706/706 [00:00&lt;00:00, 6.10kB/s]"
          }
        },
        "f430daf9df30461ca939404ffac3875b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2478f7267eb4f1a86bd816d1fdab481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5f18b8001b74c0e8182be129836724e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bb77f9351764919b456cb93188a2a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "723b75c6746947ccbf11c5190e4dd616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03de5ccd15e845228a9b2f3b98596468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9285b8b1c8a94520b4b5bbc9b4306975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21cde824b1ca40f090d692a55b6f4a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7eac339e0fe416d80fa8beeb40b08b0",
              "IPY_MODEL_cbc8a79fb263488a81d5a1a0a7058755",
              "IPY_MODEL_ee3c053d7e504e3cabf0771fe11d9d2b"
            ],
            "layout": "IPY_MODEL_4ce8f8eddb914764aeacc433dde4165c"
          }
        },
        "e7eac339e0fe416d80fa8beeb40b08b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3192edbf6f6d4323a273c15e36af85ce",
            "placeholder": "​",
            "style": "IPY_MODEL_b0e79da5eb8e4071bf68928eb801a068",
            "value": "tokenizer.json: 100%"
          }
        },
        "cbc8a79fb263488a81d5a1a0a7058755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea1d9c5204634ccaa2662abf8bfe1214",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4abc58759696495ab67ec952d3a01581",
            "value": 711396
          }
        },
        "ee3c053d7e504e3cabf0771fe11d9d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c2935317f9c4913b3de05109d5b7383",
            "placeholder": "​",
            "style": "IPY_MODEL_1069847b745443bea9f32a137309f2de",
            "value": " 711k/711k [00:00&lt;00:00, 2.19MB/s]"
          }
        },
        "4ce8f8eddb914764aeacc433dde4165c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3192edbf6f6d4323a273c15e36af85ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e79da5eb8e4071bf68928eb801a068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea1d9c5204634ccaa2662abf8bfe1214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4abc58759696495ab67ec952d3a01581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c2935317f9c4913b3de05109d5b7383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1069847b745443bea9f32a137309f2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e8cb193760c4feba848e2d5cb4c6037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_894b2eb0b77d4f7c89f8997257d4f594",
              "IPY_MODEL_b26b1c1b548048238a9770cef5b1a26a",
              "IPY_MODEL_d019d741cdc949ecb76bd18fd716a250"
            ],
            "layout": "IPY_MODEL_95f6c4b664f94ed584ecc6f4b6ee659a"
          }
        },
        "894b2eb0b77d4f7c89f8997257d4f594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a774b3fb0f84a4c8689769eaa91e55b",
            "placeholder": "​",
            "style": "IPY_MODEL_1498e69f3cc642c4b464365ba10f1f24",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b26b1c1b548048238a9770cef5b1a26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5634192c4a4c8cb8611c3da274b9b8",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81131cc1723542dbb61bea2637498b17",
            "value": 695
          }
        },
        "d019d741cdc949ecb76bd18fd716a250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36e1c0c5d3b54609ad01b631074a7d85",
            "placeholder": "​",
            "style": "IPY_MODEL_317799643b944339966ab478bbdcf2f3",
            "value": " 695/695 [00:00&lt;00:00, 30.3kB/s]"
          }
        },
        "95f6c4b664f94ed584ecc6f4b6ee659a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a774b3fb0f84a4c8689769eaa91e55b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1498e69f3cc642c4b464365ba10f1f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c5634192c4a4c8cb8611c3da274b9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81131cc1723542dbb61bea2637498b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36e1c0c5d3b54609ad01b631074a7d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317799643b944339966ab478bbdcf2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XaxUser/Projects/blob/main/smolagents_doc/en/agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch streamlit pdfplumber python-dotenv langgraph langchain chromadb langchain_chroma langchain_community langchain_experimental chunking langchain_docling google-generativeai langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKN5P0--LcBe",
        "outputId": "ab7a9b2d-4a48-403f-ba49-a15869404698"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting chunking\n",
            "  Downloading Chunking-0.0.2.tar.gz (1.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain_docling\n",
            "  Downloading langchain_docling-1.0.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.63)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.44)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-4.8.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.72.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting docling~=2.18 (from langchain_docling)\n",
            "  Downloading docling-2.36.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.171.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting docling-core<3.0.0,>=2.29.0 (from docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling)\n",
            "  Downloading docling_core-2.36.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting docling-ibm-models<4.0.0,>=3.4.4 (from docling~=2.18->langchain_docling)\n",
            "  Downloading docling_ibm_models-3.4.4-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting docling-parse<5.0.0,>=4.0.0 (from docling~=2.18->langchain_docling)\n",
            "  Downloading docling_parse-4.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.11/dist-packages (from docling~=2.18->langchain_docling) (0.32.4)\n",
            "Collecting easyocr<2.0,>=1.7 (from docling~=2.18->langchain_docling)\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from docling~=2.18->langchain_docling) (2025.4.26)\n",
            "Collecting rtree<2.0.0,>=1.3.0 (from docling~=2.18->langchain_docling)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting python-docx<2.0.0,>=1.1.2 (from docling~=2.18->langchain_docling)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from docling~=2.18->langchain_docling)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from docling~=2.18->langchain_docling) (4.13.4)\n",
            "Collecting marko<3.0.0,>=2.1.2 (from docling~=2.18->langchain_docling)\n",
            "  Downloading marko-2.1.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from docling~=2.18->langchain_docling) (3.1.5)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling~=2.18->langchain_docling) (5.4.0)\n",
            "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from docling~=2.18->langchain_docling) (1.6.0)\n",
            "Collecting pylatexenc<3.0,>=2.10 (from docling~=2.18->langchain_docling)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from docling~=2.18->langchain_docling) (1.15.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling~=2.18->langchain_docling) (2.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling) (0.9.0)\n",
            "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling)\n",
            "  Downloading latex2mathml-3.78.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling)\n",
            "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling) (4.52.4)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.4->docling~=2.18->langchain_docling) (0.21.0+cu124)\n",
            "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4.0.0,>=3.4.4->docling~=2.18->langchain_docling)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.4->docling~=2.18->langchain_docling) (4.11.0.86)\n",
            "Requirement already satisfied: safetensors<1,>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4.0.0,>=3.4.4->docling~=2.18->langchain_docling) (0.5.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling~=2.18->langchain_docling) (0.25.2)\n",
            "Collecting python-bidi (from easyocr<2.0,>=1.7->docling~=2.18->langchain_docling)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling~=2.18->langchain_docling) (2.1.1)\n",
            "Collecting pyclipper (from easyocr<2.0,>=1.7->docling~=2.18->langchain_docling)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr<2.0,>=1.7->docling~=2.18->langchain_docling)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling~=2.18->langchain_docling) (1.1.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.22.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling~=2.18->langchain_docling) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling~=2.18->langchain_docling)\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling)\n",
            "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling) (2024.11.6)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling~=2.18->langchain_docling) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling~=2.18->langchain_docling) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling~=2.18->langchain_docling) (0.4)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.11/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling) (0.70.15)\n",
            "Requirement already satisfied: dill>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling~=2.18->langchain_docling) (0.3.7)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
            "Downloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_docling-1.0.0-py3-none-any.whl (5.6 kB)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading docling-2.36.1-py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.3/178.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.55b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-4.8.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading docling_core-2.36.0-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_ibm_models-3.4.4-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_parse-4.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marko-2.1.3-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading latex2mathml-3.78.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: chunking, pypika, pylatexenc\n",
            "  Building wheel for chunking (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chunking: filename=Chunking-0.0.2-py3-none-any.whl size=2069 sha256=ce01c4a4ac8a4a06b48ed6184fa160539023389f065a2ad4d9ea61c95ec62b40\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/c6/3d/77bbcd4ec21b00d3174b3c56272922182f6b17bc574fcf1ebc\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=cc3855d29ce5fbcfd84d055732020f15f38cacfefac0b6f2800c3ad458eda60a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=19a36b18cab1f170dd96c5d839c3e3a34c626f7a76de8bf24497e8aae9b63a9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/7a/33/9fdd892f784ed4afda62b685ae3703adf4c91aa0f524c28f03\n",
            "Successfully built chunking pypika pylatexenc\n",
            "Installing collected packages: python-bidi, pypika, pylatexenc, pyclipper, filetype, durationpy, chunking, XlsxWriter, watchdog, uvloop, rtree, python-dotenv, python-docx, pypdfium2, overrides, ormsgpack, opentelemetry-util-http, opentelemetry-proto, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, mypy-extensions, mpire, mmh3, marshmallow, marko, latex2mathml, jsonref, jsonlines, humanfriendly, httpx-sse, httptools, bcrypt, backoff, asgiref, watchfiles, typing-inspect, starlette, python-pptx, pydeck, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, semchunk, pydantic-settings, pdfminer.six, opentelemetry-semantic-conventions, onnxruntime, nvidia-cusolver-cu12, langsmith, langgraph-sdk, kubernetes, fastapi, dataclasses-json, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, docling-core, streamlit, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, docling-parse, opentelemetry-instrumentation-fastapi, langgraph-prebuilt, easyocr, docling-ibm-models, langgraph, langchain_google_genai, langchain_community, docling, chromadb, langchain_experimental, langchain_docling, langchain_chroma\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.46.2\n",
            "    Uninstalling starlette-0.46.2:\n",
            "      Successfully uninstalled starlette-0.46.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.44\n",
            "    Uninstalling langsmith-0.3.44:\n",
            "      Successfully uninstalled langsmith-0.3.44\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.115.12\n",
            "    Uninstalling fastapi-0.115.12:\n",
            "      Successfully uninstalled fastapi-0.115.12\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.63\n",
            "    Uninstalling langchain-core-0.3.63:\n",
            "      Successfully uninstalled langchain-core-0.3.63\n",
            "Successfully installed XlsxWriter-3.2.3 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.12 chunking-0.0.2 coloredlogs-15.0.1 dataclasses-json-0.6.7 docling-2.36.1 docling-core-2.36.0 docling-ibm-models-3.4.4 docling-parse-4.0.4 durationpy-0.10 easyocr-1.7.2 fastapi-0.115.9 filetype-1.2.0 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 jsonlines-3.1.0 jsonref-1.1.0 kubernetes-33.1.0 langchain-core-0.3.65 langchain_chroma-0.2.4 langchain_community-0.3.25 langchain_docling-1.0.0 langchain_experimental-0.3.4 langchain_google_genai-2.0.10 langgraph-0.4.8 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 langsmith-0.3.45 latex2mathml-3.78.0 marko-2.1.3 marshmallow-3.26.1 mmh3-5.1.0 mpire-2.10.2 mypy-extensions-1.1.0 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-instrumentation-0.55b1 opentelemetry-instrumentation-asgi-0.55b1 opentelemetry-instrumentation-fastapi-0.55b1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 opentelemetry-util-http-0.55b1 ormsgpack-1.10.0 overrides-7.7.0 pdfminer.six-20250506 pdfplumber-0.11.7 posthog-4.8.0 pyclipper-1.3.0.post6 pydantic-settings-2.9.1 pydeck-0.9.1 pylatexenc-2.10 pypdfium2-4.30.1 pypika-0.48.9 python-bidi-0.6.6 python-docx-1.1.2 python-dotenv-1.1.0 python-pptx-1.0.2 rtree-1.4.0 semchunk-2.2.2 starlette-0.45.3 streamlit-1.45.1 typing-inspect-0.9.0 uvloop-0.21.0 watchdog-6.0.0 watchfiles-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Edpot8zMv8C",
        "outputId": "524b93b2-2067-4a01-b01e-dfcc64614346"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install fastembed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul3OJtwfNY7T",
        "outputId": "f43a7ef8-3d6d-4910-a12a-078746cab303"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastembed\n",
            "  Downloading fastembed-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.32.4)\n",
            "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: mmh3<6.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from fastembed) (2.0.2)\n",
            "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (1.22.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (11.2.1)\n",
            "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed)\n",
            "  Downloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.11/dist-packages (from fastembed) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.21.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.11/dist-packages (from fastembed) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (1.1.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (2025.4.26)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
            "Downloading fastembed-0.7.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py-rust-stemmers, loguru, fastembed\n",
            "Successfully installed fastembed-0.7.0 loguru-0.7.3 py-rust-stemmers-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7520f61d1ad542c6a708fe971c834ef6",
            "eaea33eb51584faf82f597eea55c6f61",
            "324abedc8c1f41c88fe502640c9a66e8",
            "b0b911caf03346db999c3a6ec0d219fa",
            "cb540107445446edb370a66d33ea93df",
            "3ddb2cc7599846ba93bac0da24b78864",
            "a65db16d37044da8add2f0e7880f38dd",
            "566678c2933f4eac9c085fd134528a49",
            "76e2161089a247d887b87a6b52c82158",
            "098c15235a1b4c6b8d55dc32c44dc59a",
            "fc269046964b4e619fa46b713f7dcd2e",
            "4d315cc8b188400b96af5381f80bac99",
            "08a855d6b63c46e3a2c60307d72ae6e1",
            "81c515f9e6c14aedb4d130b6ce0a39dd",
            "1e22339990e747c4816d6e35e0e9e077",
            "37c629faf44e4ae485062dee8a1cc385",
            "308baafd6eaa49098aacd0439d750e9c",
            "27f437013b6b446987c7c3a813a14d93",
            "b15000898cee41f5baae82c136b89796",
            "fe92f316fd3649989b5fb7f9f02e56cc",
            "2ac163c21546470ab9308727190304d5",
            "26c8e32bc79d4e4a8562b3b9fba7b4e0",
            "ce4f289b558e4757ae264e1ce3fa42bb",
            "4eb32830f7854d2198f4183d7c887827",
            "8d2933004c284aeaad958d53013bde0e",
            "4669c4b660a047e8ac3a97988b202187",
            "30badb34cdc0484c8122c77141d47920",
            "adfa6966d86748b1a33e535e05c4a278",
            "175fefb5ac09499d8d6f348716faa634",
            "a04a0956e9a64ffb837d533e78806718",
            "4ee1103753804c70a0f05f375766abc3",
            "2e152b19cb1041cdbc00dfd74bfa5441",
            "7f60c61967eb4c5f8abf155b20137c73",
            "7a740a6abe9e45afbe27a1072b9521d3",
            "9a39e3d554db4e1c988d52aaa0c9a870",
            "51d870df56cd4fab8298e30268ea1513",
            "1b9d5754c89f432caac8971adc5476e7",
            "f430daf9df30461ca939404ffac3875b",
            "f2478f7267eb4f1a86bd816d1fdab481",
            "a5f18b8001b74c0e8182be129836724e",
            "0bb77f9351764919b456cb93188a2a3d",
            "723b75c6746947ccbf11c5190e4dd616",
            "03de5ccd15e845228a9b2f3b98596468",
            "9285b8b1c8a94520b4b5bbc9b4306975",
            "21cde824b1ca40f090d692a55b6f4a4e",
            "e7eac339e0fe416d80fa8beeb40b08b0",
            "cbc8a79fb263488a81d5a1a0a7058755",
            "ee3c053d7e504e3cabf0771fe11d9d2b",
            "4ce8f8eddb914764aeacc433dde4165c",
            "3192edbf6f6d4323a273c15e36af85ce",
            "b0e79da5eb8e4071bf68928eb801a068",
            "ea1d9c5204634ccaa2662abf8bfe1214",
            "4abc58759696495ab67ec952d3a01581",
            "6c2935317f9c4913b3de05109d5b7383",
            "1069847b745443bea9f32a137309f2de",
            "3e8cb193760c4feba848e2d5cb4c6037",
            "894b2eb0b77d4f7c89f8997257d4f594",
            "b26b1c1b548048238a9770cef5b1a26a",
            "d019d741cdc949ecb76bd18fd716a250",
            "95f6c4b664f94ed584ecc6f4b6ee659a",
            "8a774b3fb0f84a4c8689769eaa91e55b",
            "1498e69f3cc642c4b464365ba10f1f24",
            "4c5634192c4a4c8cb8611c3da274b9b8",
            "81131cc1723542dbb61bea2637498b17",
            "36e1c0c5d3b54609ad01b631074a7d85",
            "317799643b944339966ab478bbdcf2f3"
          ]
        },
        "id": "FE7sbg0-K_47",
        "outputId": "4192320b-8730-4ac7-cb6d-1b8c62ad2220"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7520f61d1ad542c6a708fe971c834ef6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d315cc8b188400b96af5381f80bac99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce4f289b558e4757ae264e1ce3fa42bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a740a6abe9e45afbe27a1072b9521d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21cde824b1ca40f090d692a55b6f4a4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e8cb193760c4feba848e2d5cb4c6037"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Erreur avec collection 'AO_documents': Expected Embeddings to be non-empty list or numpy array, got [] in upsert.\n",
            "WARNING:__main__:Création d'une collection minimale 'AO_documents' après échecs multiples\n",
            "WARNING:__main__:Erreur avec collection 'CV_documents': Expected Embeddings to be non-empty list or numpy array, got [] in upsert.\n",
            "WARNING:__main__:Création d'une collection minimale 'CV_documents' après échecs multiples\n",
            "2025-06-12 12:55:52.670 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:52.677 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:52.961 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-06-12 12:55:52.964 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:52.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:52.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:52.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:52.972 Session state does not function when running a script without `streamlit run`\n",
            "2025-06-12 12:55:53.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.075 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.082 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.093 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.094 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.104 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.105 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.106 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.109 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.110 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.111 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.112 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.113 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.119 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-12 12:55:53.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import types\n",
        "\n",
        "# Patch pour éviter que streamlit ne tente de parcourir torch.classes\n",
        "sys.modules['torch.classes'] = types.ModuleType('torch.classes')\n",
        "import os\n",
        "import time\n",
        "import ssl\n",
        "import pickle\n",
        "import hashlib\n",
        "import warnings\n",
        "import json\n",
        "import logging\n",
        "import concurrent.futures\n",
        "from io import StringIO\n",
        "from typing import Any, Dict, List, Tuple, TypedDict, Callable\n",
        "from functools import lru_cache\n",
        "from google.colab import userdata\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# LangGraph & LangChain imports\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain.tools import Tool\n",
        "from chromadb.config import Settings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings import FastEmbedEmbeddings\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain.schema import Document\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "#from chunking import ClusterSemanticChunker\n",
        "from chromadb.utils import embedding_functions\n",
        "#from langchain_docling import DoclingLoader\n",
        "from langchain_docling.loader import DocumentConverter\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# --- Load environment variables ---\n",
        "load_dotenv()\n",
        "\n",
        "# --- Silence deprecation warnings ---\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# --- SSL certificate workaround ---\n",
        "try:\n",
        "    ssl._create_default_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "\n",
        "# --- Logging configuration ---\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler(), logging.FileHandler(\"matching_app.log\")]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "## --- Directories ---\n",
        "AGENT_STORAGE_DIR = \"storage\"\n",
        "#KB_DIR = os.path.join(AGENT_STORAGE_DIR, \"pdf_knowledge_base\")\n",
        "#CACHE_DIR = os.path.join(AGENT_STORAGE_DIR, \"cache\")\n",
        "#EMBED_CACHE = os.path.join(CACHE_DIR, \"embeddings\")\n",
        "#CHUNKS_CACHE = os.path.join(CACHE_DIR, \"chunks\")\n",
        "#for d in [AGENT_STORAGE_DIR, KB_DIR, CACHE_DIR, EMBED_CACHE, CHUNKS_CACHE]:\n",
        "#    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# --- Typed state dict ---\n",
        "class AgentState(TypedDict, total=False):\n",
        "    messages: List[Dict[str, Any]]\n",
        "    context: str\n",
        "    ao_skills: str\n",
        "    cv_skills: str\n",
        "\n",
        "# --- Caching utils ---\n",
        "#def get_file_hash(path: str) -> str:\n",
        "#    \"\"\"\n",
        "#    Calcule le hash SHA-256 d'un fichier pour le caching.\n",
        "#    Optimisé pour les gros fichiers avec lecture par chunks.\n",
        "#    \"\"\"\n",
        "#    hasher = hashlib.sha256()\n",
        "#    try:\n",
        "#        with open(path, 'rb') as f:\n",
        "#            while chunk := f.read(65536):\n",
        "#                hasher.update(chunk)\n",
        "#        return hasher.hexdigest()\n",
        "#    except Exception as e:\n",
        "#        logger.error(f\"Erreur lors du calcul du hash pour {path}: {e}\")\n",
        "#        return hashlib.sha256(path.encode()).hexdigest()  # Fallback\n",
        "#\n",
        "#def cache_path(path: str, kind: str) -> str:\n",
        "#    \"\"\"\n",
        "#    Génère un chemin de cache basé sur le hash du fichier.\n",
        "#    \"\"\"\n",
        "#    h = get_file_hash(path)[:8]\n",
        "#    name = os.path.splitext(os.path.basename(path))[0]\n",
        "#    folder = CHUNKS_CACHE if kind == 'chunks' else EMBED_CACHE\n",
        "#    return os.path.join(folder, f\"{name}_{h}_{kind}.pkl\")\n",
        "#\n",
        "#def save_cache(data: Any, path: str) -> None:\n",
        "#    \"\"\"\n",
        "#    Sauvegarde des données dans le cache avec gestion d'erreurs.\n",
        "#    \"\"\"\n",
        "#    try:\n",
        "#        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "#        with open(path, 'wb') as f:\n",
        "#            pickle.dump(data, f)\n",
        "#        logger.debug(f\"Cache sauvegardé: {path}\")\n",
        "#    except Exception as e:\n",
        "#        logger.warning(f\"Erreur lors de la sauvegarde du cache {path}: {e}\")\n",
        "#\n",
        "#def load_cache(path: str) -> Any:\n",
        "#    \"\"\"\n",
        "#    Charge des données depuis le cache avec gestion d'erreurs.\n",
        "#    \"\"\"\n",
        "#    try:\n",
        "#        if os.path.exists(path):\n",
        "#            with open(path, 'rb') as f:\n",
        "#                data = pickle.load(f)\n",
        "#            logger.debug(f\"Cache chargé: {path}\")\n",
        "#            return data\n",
        "#    except Exception as e:\n",
        "#        logger.warning(f\"Erreur lors du chargement du cache {path}: {e}\")\n",
        "#    return None\n",
        "\n",
        "def lire_mkd(chemin):\n",
        "    \"\"\"\n",
        "    Lit un fichier .mkd et retourne son contenu sous forme de chaîne de caractères.\n",
        "\n",
        "    Paramètre\n",
        "    ---------\n",
        "    chemin : str\n",
        "        Chemin vers le fichier .mkd à lire.\n",
        "\n",
        "    Retour\n",
        "    ------\n",
        "    str\n",
        "        Contenu du fichier Markdown.\n",
        "\n",
        "    Exemple\n",
        "    -------\n",
        "    >>> contenu = lire_mkd(\"mon_document.mkd\")\n",
        "    >>> print(contenu)\n",
        "    \"# Titre\\n\\nVoici le contenu Markdown...\"\n",
        "    \"\"\"\n",
        "    # Vérifier que le fichier existe\n",
        "    if not os.path.isfile(chemin):\n",
        "        raise FileNotFoundError(f\"Le fichier '{chemin}' n'existe pas.\")\n",
        "    # Vérifier que l'extension est bien .mkd\n",
        "    if not chemin.lower().endswith(\".mkd\"):\n",
        "        raise ValueError(f\"Le fichier '{chemin}' n'a pas l'extension .mkd.\")\n",
        "\n",
        "    # Lecture du fichier en UTF-8 (adapter l'encodage si besoin)\n",
        "    with open(chemin, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()\n",
        "\n",
        "# --- PDF extraction ---\n",
        "def extract_text_and_tables(pdf_path: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Extrait le texte et les tableaux d'un PDF avec multithreading.\n",
        "    Optimisé pour la performance et la robustesse.\n",
        "    \"\"\"\n",
        "    all_contents = []\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for i, page in enumerate(pdf.pages):\n",
        "            if i == 1:\n",
        "                continue\n",
        "            text = page.extract_text()\n",
        "            if \"6. CONDITIONS\" in text:\n",
        "                L = text.split(\"6. CONDITIONS\")\n",
        "                if len(L)>1:\n",
        "                    all_contents.append((\"texte\", L[0].strip()))\n",
        "                break\n",
        "            text = text.replace(\"© Copyright Orange 2025\",\"\")\n",
        "            text = text.replace(\"Document confidentiel\",\"\")\n",
        "            text = text.replace(\"La communication de ce document est soumise à autorisation d'Orange\",\"\")\n",
        "            if text:\n",
        "                all_contents.append((\"texte\", text.strip()))\n",
        "\n",
        "            tables = page.extract_tables()\n",
        "            for table in tables:\n",
        "                # Nettoyer le tableau et le transformer en texte structuré\n",
        "                #table_text = \"\\n\".join([\" | \".join(cell.strip() for cell in row if cell) for row in table])\n",
        "                table_text = \"\"\n",
        "                headers = table[0]\n",
        "                for row in table[1:]:\n",
        "                    for header, cell in zip(headers, row):\n",
        "                        if header and cell:\n",
        "                            table_text += f\"{header.strip()} : {cell.strip()}\\n\"\n",
        "                    table_text += \"\\n\"\n",
        "                if table_text:\n",
        "                    all_contents.append((\"tableau\", table_text.strip()))\n",
        "\n",
        "    return all_contents\n",
        "\n",
        "# --- Embeddings & vector stores ---\n",
        "# Configuration des embeddings avec cache\n",
        "embeddings = FastEmbedEmbeddings(\n",
        "    #model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    #cache_folder=EMBED_CACHE,\n",
        "    max_seq_length=512,\n",
        "    #doc_embed_type=\"passage\"\n",
        ")\n",
        "\n",
        "# Configuration de ChromaDB\n",
        "settings = Settings(\n",
        "    anonymized_telemetry=False,\n",
        "    allow_reset=True,  # Permettre la réinitialisation des collections\n",
        "    is_persistent=False\n",
        ")\n",
        "\n",
        "# --- Semantic chunking ---\n",
        "def create_semantic_chunks(texts: List[str], file_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Crée des chunks sémantiques à partir des textes extraits.\n",
        "    Utilise le cache pour éviter de retraiter les mêmes documents.\n",
        "    Optimisé pour différentes tailles de documents.\n",
        "    \"\"\"\n",
        "    # Vérifier le cache\n",
        "    #cpath = cache_path(file_path, 'chunks')\n",
        "    #cached = load_cache(cpath)\n",
        "    #if cached:\n",
        "    #    logger.info(f\"Utilisation du cache pour les chunks: {file_path}\")\n",
        "    #    return cached\n",
        "\n",
        "    # Adapter les paramètres de chunking en fonction de la taille du document\n",
        "    total_len = sum(len(t) for t in texts)\n",
        "    logger.info(f\"Taille totale du texte: {total_len} caractères\")\n",
        "\n",
        "    if total_len < 10000:\n",
        "        max_size, min_size = 300, 100\n",
        "    elif total_len < 50000:\n",
        "        max_size, min_size = 500, 150\n",
        "    else:\n",
        "        max_size, min_size = 12000, 200\n",
        "\n",
        "    try:\n",
        "        # Créer les chunks avec gestion d'erreurs\n",
        "        splitter = SemanticChunker(\n",
        "            embeddings=embeddings,\n",
        "            min_chunk_size=min_size,\n",
        "            #add_start_index=True,  # Ajouter l'index de début pour faciliter le débogage\n",
        "            #breakpoint_threshold_type='percentile',  # Méthode robuste pour découpage\n",
        "            #breakpoint_threshold_amount=5,\n",
        "            #sentence_split_regex= r\"(?<=[.?!])\\s+#\"\n",
        "        )\n",
        "\n",
        "        #splitter = ClusterSemanticChunker(\n",
        "        #    embedding_function=embedding_functions.DefaultEmbeddingFunction(),\n",
        "        #    max_chunk_size=1200,\n",
        "        #    min_chunk_size=400\n",
        "        #) #800-400 70\n",
        "\n",
        "        # Filtrer les textes vides ou trop courts\n",
        "        #print(texts)\n",
        "        if len(texts[0]) >10:\n",
        "            valid_texts = texts[0]\n",
        "        else:\n",
        "            valid_texts = texts # and len(t.strip()) > 20]\n",
        "        #print(valid_texts)\n",
        "        if not valid_texts:\n",
        "            logger.warning(f\"Aucun texte valide à chunker pour {file_path}\")\n",
        "            return []\n",
        "\n",
        "        # Créer les documents\n",
        "        #docs_raw = splitter.create_documents(valid_texts)\n",
        "        docs_raw = splitter.split_text(valid_texts)\n",
        "        #docs_raw = \"\\n\\n\".join(valid_texts)\n",
        "        #docs_raw = valid_texts.split(\"##\")\n",
        "        valid_texts = [text for text in valid_texts if len(text.strip()) > 20]\n",
        "        #print(docs_raw)\n",
        "        logger.info(f\"Chunks créés: {len(docs_raw)} chunks\")\n",
        "        docs = [Document(page_content=chunk, metadata={\"source\": os.path.basename(file_path)}) for chunk in docs_raw]\n",
        "\n",
        "        # Vérifier que les chunks ont été créés correctement\n",
        "        if not docs:\n",
        "            logger.warning(f\"Aucun chunk créé pour {file_path}\")\n",
        "            return []\n",
        "\n",
        "        # Sauvegarder dans le cache\n",
        "        #save_cache(docs, cpath)\n",
        "        logger.info(f\"Chunks créés et mis en cache: {len(docs)} chunks\")\n",
        "\n",
        "        return docs\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erreur lors du chunking pour {file_path}: {e}\", exc_info=True)\n",
        "        return []\n",
        "\n",
        "# --- Gestion améliorée des collections ChromaDB ---\n",
        "def create_or_get_collection(name: str) -> Chroma:\n",
        "    \"\"\"\n",
        "    Crée une nouvelle collection ChromaDB ou récupère une existante.\n",
        "    Gère les erreurs de manière robuste avec retry et backoff exponentiel.\n",
        "    \"\"\"\n",
        "    collection_id = hashlib.md5(name.encode()).hexdigest()\n",
        "\n",
        "    logger.info(f\"Tentative de création/récupération de la collection '{name}' (ID: {collection_id})\")\n",
        "\n",
        "    try:\n",
        "        # Tentative de création d'une nouvelle collection\n",
        "        store = Chroma.from_documents(\n",
        "            documents=[],  # Collection vide\n",
        "            embedding=embeddings,\n",
        "            collection_name=collection_id,  # Utiliser un ID stable basé sur le hash du nom\n",
        "            client_settings=settings\n",
        "        )\n",
        "\n",
        "        # Vérifier que la collection est accessible\n",
        "        try:\n",
        "            count = len(store.get())\n",
        "            logger.info(f\"Collection '{name}' (ID: {collection_id}) créée/récupérée avec succès: {count} documents\")\n",
        "            return store\n",
        "        except Exception as inner_e:\n",
        "            logger.warning(f\"Collection '{name}' créée mais non accessible: {inner_e}\")\n",
        "            # Continuer pour réessayer\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Erreur avec collection '{name}': {e}\")\n",
        "\n",
        "    # Si toutes les tentatives ont échoué, créer une collection minimale en dernier recours\n",
        "    logger.warning(f\"Création d'une collection minimale '{name}' après échecs multiples\")\n",
        "    return Chroma(\n",
        "        collection_name=collection_id,\n",
        "        embedding_function=embeddings,\n",
        "        client_settings=settings\n",
        "    )\n",
        "\n",
        "\n",
        "# Initialisation des stores avec la nouvelle fonction robuste\n",
        "global vector_store_AO\n",
        "vector_store_AO = create_or_get_collection(f\"AO_documents\")\n",
        "global vector_store_CV\n",
        "vector_store_CV = create_or_get_collection(f\"CV_documents\")\n",
        "\n",
        "# --- PDF ingestion ---\n",
        "def ingest_pdf(path: str, dtype: str) -> str:\n",
        "    \"\"\"\n",
        "    Fonction d'ingestion PDF améliorée avec gestion d'erreurs robuste.\n",
        "    Optimisée pour la performance et la fiabilité.\n",
        "    \"\"\"\n",
        "\n",
        "    start_time = time.time()\n",
        "    logger.info(f\"Début d'ingestion du PDF {path} (type: {dtype})\")\n",
        "\n",
        "    # Validation des entrées\n",
        "    if not os.path.exists(path):\n",
        "        return f\"Erreur: {path} introuvable\"\n",
        "    #if not path.lower().endswith('.mkd'):\n",
        "    #    return \"Erreur: fournir un PDF\"\n",
        "\n",
        "    # Sélection du store approprié\n",
        "    store_name = \"AO_documents\" if dtype=='AO' else \"CV_documents\"\n",
        "    collection_id = hashlib.md5(store_name.encode()).hexdigest()\n",
        "\n",
        "    try:\n",
        "        # Récréer la collection\n",
        "        if dtype == 'AO':\n",
        "            global vector_store_AO\n",
        "            vector_store_AO = reset_vector_store(\"AO_documents\")\n",
        "            store = vector_store_AO\n",
        "        else:\n",
        "            global vector_store_CV\n",
        "            vector_store_CV = reset_vector_store(\"CV_documents\")\n",
        "            store = vector_store_CV\n",
        "\n",
        "        # Extraction du contenu avec mesure de performance\n",
        "        extract_start = time.time()\n",
        "        logger.info(f\"Extraction du contenu du PDF {path}...\")\n",
        "        #content = extract_text_and_tables(path)\n",
        "        #content = DocumentConverter().convert(path)  #.document.export_to_markdown()\n",
        "        #content = [content.document.export_to_markdown()]\n",
        "        if path.lower().endswith('.pdf'):\n",
        "            content = DocumentConverter().convert(path)  #.document.export_to_markdown()\n",
        "            content = [content.document.export_to_markdown()]\n",
        "        else:\n",
        "            content = lire_mkd(path)\n",
        "        extract_time = time.time() - extract_start\n",
        "        logger.info(f\"Extraction terminée en {extract_time:.2f}s: {len(content)} éléments extraits\")\n",
        "\n",
        "        if not content:\n",
        "            return f\"Aucun contenu extrait de {os.path.basename(path)}\"\n",
        "\n",
        "        # Création des chunks avec mesure de performance\n",
        "        chunk_start = time.time()\n",
        "        logger.info(f\"Création des chunks sémantiques...\")\n",
        "        texts = content # [c for c in content]\n",
        "        docs = create_semantic_chunks(texts, path)\n",
        "        chunk_time = time.time() - chunk_start\n",
        "        logger.info(f\"Chunking terminé en {chunk_time:.2f}s: {len(docs)} chunks créés\")\n",
        "\n",
        "        if not docs:\n",
        "            return f\"Chunking échoué pour {os.path.basename(path)}\"\n",
        "\n",
        "        # Ajout des documents avec mesure de performance\n",
        "        embed_start = time.time()\n",
        "        logger.info(f\"Ajout des documents au vector store...\")\n",
        "\n",
        "        # Ajout par lots pour éviter les timeouts\n",
        "        batch_size = 50\n",
        "        for i in range(0, len(docs), batch_size):\n",
        "            batch = docs[i:i+batch_size]\n",
        "            try:\n",
        "                store.add_documents(batch)\n",
        "                logger.info(f\"Lot {i//batch_size + 1}/{(len(docs)-1)//batch_size + 1} ajouté ({len(batch)} docs)\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Erreur lors de l'ajout du lot {i//batch_size + 1}: {e}\")\n",
        "                # Continuer avec le lot suivant\n",
        "\n",
        "        embed_time = time.time() - embed_start\n",
        "        logger.info(f\"Embedding et indexation terminés en {embed_time:.2f}s\")\n",
        "\n",
        "        # Vérification finale\n",
        "        try:\n",
        "            count = len(store.get())\n",
        "            logger.info(f\"Documents dans {store_name} (ID: {collection_id}): {count}\")\n",
        "\n",
        "            if count == 0:\n",
        "                return f\"Avertissement: Aucun document n'a été ajouté à {store_name}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Impossible de vérifier le nombre de documents: {e}\")\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        return f\"Ingestion réussie de {os.path.basename(path)} en {total_time:.2f}s\"\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ingestion failed for {path}\", exc_info=True)\n",
        "        return f\"Erreur: {str(e)}\"\n",
        "\n",
        "def ingest_pdf_document_AO(fp: str) -> str:\n",
        "    return ingest_pdf(fp, 'AO')\n",
        "\n",
        "def ingest_pdf_document_CV(fp: str) -> str:\n",
        "    return ingest_pdf(fp, 'CV')\n",
        "\n",
        "# --- LLM setup ---\n",
        "@lru_cache(maxsize=1)\n",
        "def get_llm(temperature=0.7, top_p=0.9, top_k=40):\n",
        "    \"\"\"\n",
        "    Obtient une instance du LLM avec cache pour éviter les réinitialisations inutiles.\n",
        "    Paramètres optimisés pour différentes tâches.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-1.5-flash\",  # Ou \"gemini-2.5-pro\" si disponible via l'API\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            convert_system_message_to_human=True  # selon les besoins\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erreur lors de l'initialisation du LLM: {e}\")\n",
        "        # Fallback avec paramètres minimaux\n",
        "        return ChatOllama(model=\"gemma3:1b\")\n",
        "\n",
        "# --- Prompts améliorés avec Chain-of-Thought et exemples few-shot ---\n",
        "\n",
        "#AO_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en analyse de documents d'appels d'offres (AO), spécialisé dans l'extraction et la catégorisation des compétences, technologies et exigences.\n",
        "#\n",
        "#**Votre tâche:**\n",
        "#1. **Extraire** toutes les compétences techniques, soft skills, technologies, frameworks, certifications et exigences d'expérience.\n",
        "#2. **Catégoriser** chaque élément en:\n",
        "#   - **Compétences techniques** (ex: Python, Docker)\n",
        "#   - **Soft skills** (ex: Gestion de projet, Leadership d'équipe)\n",
        "#   - **Certifications** (ex: PMP, AWS Certified)\n",
        "#   - **Exigences d'expérience** (ex: \"5+ ans en architecture cloud\")\n",
        "#3. **Évaluer** l'importance de chaque élément:\n",
        "#   - **Critique** (obligatoire, mentionné comme essentiel)\n",
        "#   - **Important** (fortement souhaité mais pas obligatoire)\n",
        "#   - **Souhaitable** (mentionné comme un plus)\n",
        "#\n",
        "#**Processus d'analyse:**\n",
        "#1. D'abord, lisez attentivement tout le contexte fourni\n",
        "#2. Identifiez toutes les compétences et exigences mentionnées\n",
        "#3. Pour chaque compétence, déterminez sa catégorie\n",
        "#4. Évaluez l'importance de chaque compétence en fonction du contexte\n",
        "#5. Organisez les résultats par catégorie et importance\n",
        "#\n",
        "#**Format de sortie:**\n",
        "#```\n",
        "### Compétences techniques\n",
        "#- [Nom de la compétence] (Critique/Important/Souhaitable): [Description ou exigence spécifique]\n",
        "#\n",
        "### Soft skills\n",
        "#- [Nom de la compétence] (Critique/Important/Souhaitable): [Description ou exigence spécifique]\n",
        "#\n",
        "### Certifications\n",
        "#- [Nom de la certification] (Critique/Important/Souhaitable): [Description ou exigence spécifique]\n",
        "#\n",
        "### Exigences d'expérience\n",
        "#- [Description de l'expérience] (Critique/Important/Souhaitable): [Détails supplémentaires]\n",
        "#```\n",
        "#\n",
        "#**Exemple:**\n",
        "#```\n",
        "### Compétences techniques\n",
        "#- Python (Critique): Maîtrise de Python 3.8+ pour le développement backend\n",
        "#- Docker (Important): Expérience avec la conteneurisation et Docker Compose\n",
        "#- React (Souhaitable): Connaissance de base pour collaborer avec l'équipe frontend\n",
        "#\n",
        "### Soft skills\n",
        "#- Gestion de projet (Critique): Capacité à gérer des projets Agile de bout en bout\n",
        "#- Communication (Important): Excellentes compétences en communication écrite et orale\n",
        "#\n",
        "### Certifications\n",
        "#- AWS Solutions Architect (Souhaitable): Certification professionnelle préférée\n",
        "#\n",
        "### Exigences d'expérience\n",
        "#- Développement cloud (Critique): Minimum 3 ans d'expérience en développement d'applications cloud\n",
        "#```\n",
        "#\n",
        "#Basez votre analyse UNIQUEMENT sur le contenu du document fourni. N'inventez pas d'informations qui ne sont pas explicitement mentionnées.\n",
        "#\"\"\"\n",
        "#\n",
        "#CV_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en analyse de CV (Curriculum Vitae), spécialisé dans l'extraction et l'évaluation des compétences et expériences professionnelles.\n",
        "#\n",
        "#**Votre tâche:**\n",
        "#1. **Extraire** toutes les compétences techniques, soft skills, certifications et expériences pertinentes du CV.\n",
        "#2. **Évaluer** le niveau de maîtrise pour chaque compétence sur une échelle de 1 à 4:\n",
        "#   - **1 = Basique**: Connaissance fondamentale, peu d'expérience pratique\n",
        "#   - **2 = Intermédiaire**: Bonne connaissance, quelques projets/expériences\n",
        "#   - **3 = Avancé**: Maîtrise solide, expérience significative\n",
        "#   - **4 = Expert**: Expertise approfondie, longue expérience, contributions notables\n",
        "#3. **Estimer** un pourcentage de confiance pour chaque évaluation.\n",
        "#\n",
        "#**Processus d'analyse:**\n",
        "#1. D'abord, lisez attentivement tout le CV\n",
        "#2. Identifiez toutes les compétences mentionnées explicitement\n",
        "#3. Déduisez les compétences implicites à partir des expériences décrites\n",
        "#4. Pour chaque compétence:\n",
        "#   - Évaluez le niveau en fonction de la durée d'expérience, des projets réalisés et du contexte\n",
        "#   - Estimez un pourcentage de confiance basé sur la clarté des informations\n",
        "#5. Organisez les résultats par catégorie\n",
        "#\n",
        "#**Format de sortie:**\n",
        "#```\n",
        "### Compétences techniques\n",
        "#- [Nom de la compétence] - [Niveau]/4: [Justification basée sur le CV]\n",
        "#\n",
        "### Soft skills\n",
        "#- [Nom de la compétence] - [Niveau]/4: [Justification basée sur le CV]\n",
        "#\n",
        "### Certifications\n",
        "#- [Nom de la certification] - [Année obtenue si mentionnée]\n",
        "#\n",
        "### Expériences clés\n",
        "#- [Description concise de l'expérience] - [Durée]: [Compétences démontrées]\n",
        "#```\n",
        "#\n",
        "#**Exemple:**\n",
        "#```\n",
        "### Compétences techniques\n",
        "#- Python - 3/4: 5 ans d'expérience, développement de plusieurs applications backend\n",
        "#- Docker - 2/4: Mentionné dans 2 projets récents, utilisation basique\n",
        "#- AWS - 4/4 : Certification AWS, 7 ans d'expérience, architecture de solutions complexes\n",
        "#\n",
        "### Soft skills\n",
        "#- Gestion de projet - 3/4: A dirigé 3 équipes de développement, méthodologie Agile\n",
        "#- Communication - 2/4: Présentations clients mentionnées, pas de détails spécifiques\n",
        "#\n",
        "### Certifications\n",
        "#- AWS Solutions Architect Professional - 2022\n",
        "#- Scrum Master Certified - 2020\n",
        "#\n",
        "### Expériences clés\n",
        "#- Architecte Cloud chez TechCorp - 3 ans: Conception et implémentation d'infrastructures AWS\n",
        "#- Lead Developer chez StartupXYZ - 2 ans: Développement Python, gestion d'équipe\n",
        "#```\n",
        "#\n",
        "#Basez votre analyse UNIQUEMENT sur le contenu du CV fourni. N'inventez pas d'informations qui ne sont pas explicitement ou implicitement présentes dans le document.\n",
        "#\"\"\"\n",
        "#\n",
        "#MATCHER_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en matching de compétences, spécialisé dans la comparaison des exigences d'un Appel d'Offres (AO) avec les compétences présentes dans un CV.\n",
        "#\n",
        "#**Votre tâche:**\n",
        "#1. **Analyser** les compétences requises dans l'AO et celles présentes dans le CV\n",
        "#2. **Identifier** les correspondances, les lacunes et les atouts supplémentaires\n",
        "#3. **Évaluer** la qualité de chaque correspondance\n",
        "#4. **Fournir** une analyse détaillée et des recommandations\n",
        "#\n",
        "#**Processus d'analyse:**\n",
        "#1. D'abord, examinez attentivement les deux listes de compétences\n",
        "#2. Pour chaque compétence requise dans l'AO:\n",
        "#   - Recherchez la compétence correspondante dans le CV\n",
        "#   - Évaluez si le niveau de compétence du CV répond à l'exigence de l'AO\n",
        "#   - Tenez compte de l'importance de la compétence dans l'AO\n",
        "#3. Identifiez les compétences critiques manquantes\n",
        "#4. Repérez les compétences supplémentaires du CV qui pourraient être valorisées\n",
        "#5. Calculez un score global d'adéquation\n",
        "#\n",
        "#**Format de sortie:**\n",
        "#```\n",
        "## Analyse de correspondance AO-CV\n",
        "#\n",
        "### Score global d'adéquation: [X]%\n",
        "#\n",
        "### Correspondances fortes\n",
        "#- [Compétence]: AO requiert [niveau d'importance], CV montre [niveau de maîtrise] (Excellente correspondance)\n",
        "#  > Justification: [Explication détaillée]\n",
        "#\n",
        "### Correspondances acceptables\n",
        "#- [Compétence]: AO requiert [niveau d'importance], CV montre [niveau de maîtrise] (Correspondance suffisante)\n",
        "#  > Justification: [Explication détaillée]\n",
        "#\n",
        "### Correspondances faibles\n",
        "#- [Compétence]: AO requiert [niveau d'importance], CV montre [niveau de maîtrise] (Amélioration nécessaire)\n",
        "#  > Justification: [Explication détaillée]\n",
        "#  > Recommandation: [Suggestion pour combler l'écart]\n",
        "#\n",
        "### Compétences critiques manquantes\n",
        "#- [Compétence]: AO requiert [niveau d'importance] (Absente du CV)\n",
        "#  > Impact: [Évaluation de l'impact sur la candidature]\n",
        "#  > Recommandation: [Suggestion pour combler cette lacune]\n",
        "#\n",
        "### Atouts supplémentaires\n",
        "#- [Compétence]: CV montre [niveau de maîtrise] (Non requise mais valorisable)\n",
        "#  > Valeur ajoutée: [Explication de la valeur potentielle]\n",
        "#\n",
        "### Recommandation finale\n",
        "#[Analyse synthétique de l'adéquation globale et recommandations stratégiques]\n",
        "#```\n",
        "#\n",
        "#**Exemple de raisonnement:**\n",
        "#1. L'AO demande \"Python (Critique)\" et le CV montre \"Python - 3/4\"\n",
        "#   → C'est une correspondance forte car le niveau est avancé pour une exigence critique\n",
        "#2. L'AO demande \"AWS (Important)\" mais le CV ne mentionne pas AWS\n",
        "#   → C'est une compétence importante manquante qui pourrait affecter la candidature\n",
        "#3. Le CV mentionne \"Docker - 4/4\" qui n'est pas explicitement requis dans l'AO\n",
        "#   → C'est un atout supplémentaire qui pourrait être valorisé\n",
        "#\n",
        "#Basez votre analyse UNIQUEMENT sur les informations fournies dans les listes de compétences. Soyez précis, objectif et constructif dans vos évaluations.\n",
        "#\"\"\"\n",
        "\n",
        "#AO_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en AO. À partir d’un document, extrayez et classez :\n",
        "#\n",
        "#1. Compétences techniques (p. ex. Python, Docker)\n",
        "#2. Soft skills (p. ex. gestion de projet, leadership)\n",
        "#3. Certifications (p. ex. PMP, AWS Certified)\n",
        "#4. Exigences d’expérience (p. ex. « 5+ ans cloud »)\n",
        "#\n",
        "#Pour chaque élément, indiquez :\n",
        "#- Catégorie\n",
        "#- Niveau d’importance : Critique (obligatoire), Important (fortement souhaité), Souhaitable (atout)\n",
        "#- Détail ou citation du texte source\n",
        "#\n",
        "#Répondez au format :\n",
        "#\n",
        "### Compétences techniques\n",
        "#- [Nom] (Critique/Important/Souhaitable) : [Extrait de l’AO]\n",
        "#\n",
        "### Soft skills\n",
        "#- …\n",
        "#\n",
        "### Certifications\n",
        "#- …\n",
        "#\n",
        "### Exigences d’expérience\n",
        "#- …\n",
        "#Basez votre analyse UNIQUEMENT sur les informations fournies dans les listes de compétences. Soyez précis, objectif et constructif dans vos évaluations.\n",
        "#\"\"\"\n",
        "#\n",
        "#CV_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en CV. À partir d’un CV, extrayez et évaluez :\n",
        "#\n",
        "#1. Compétences techniques\n",
        "#2. Soft skills\n",
        "#3. Certifications\n",
        "#4. Expériences clés\n",
        "#\n",
        "#Pour chaque compétence, indiquez :\n",
        "#- Niveau (1–4) : 1=basique, 2=intermédiaire, 3=avancé, 4=expert\n",
        "#- Confiance (en %)\n",
        "#- Justification tirée du CV\n",
        "#\n",
        "#Répondez au format :\n",
        "#\n",
        "### Compétences techniques\n",
        "#- [Nom] – [Niveau]/4 (Confiance %) : [Justification]\n",
        "#\n",
        "### Soft skills\n",
        "#- …\n",
        "#\n",
        "### Certifications\n",
        "#- [Nom] – [Année]\n",
        "#\n",
        "### Expériences clés\n",
        "#- [Poste, entreprise, durée] : [Compétences démontrées]\n",
        "#Basez votre analyse UNIQUEMENT sur les informations fournies dans les listes de compétences. Soyez précis, objectif et constructif dans vos évaluations.\n",
        "#\"\"\"\n",
        "#\n",
        "#MATCHER_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en matching AO–CV. À partir de deux listes (AO & CV), réalisez :\n",
        "#\n",
        "#1. Score global (%) d’adéquation\n",
        "#2. Correspondances fortes\n",
        "#3. Correspondances acceptables\n",
        "#4. Correspondances faibles (avec recommandations)\n",
        "#5. Compétences critiques manquantes (impact & recommandations)\n",
        "#6. Atouts supplémentaires (valeur ajoutée)\n",
        "#\n",
        "#Pour chaque point, mentionnez :\n",
        "#- Compétence\n",
        "#- Importance AO vs. niveau CV\n",
        "#- Justification\n",
        "#\n",
        "#Format de réponse :\n",
        "#\n",
        "## Matching AO–CV\n",
        "#\n",
        "### Score global : X %\n",
        "#\n",
        "#### Correspondances fortes\n",
        "#- …\n",
        "#\n",
        "#### Correspondances acceptables\n",
        "#- …\n",
        "#\n",
        "#### Correspondances faibles\n",
        "#- …\n",
        "#\n",
        "#### Critiques manquantes\n",
        "#- …\n",
        "#\n",
        "#### Atouts supplémentaires\n",
        "#- …\n",
        "#\n",
        "#### Synthèse et recommandations finales\n",
        "#Basez votre analyse UNIQUEMENT sur les informations fournies dans les listes de compétences. Soyez précis, objectif et constructif dans vos évaluations.\n",
        "#\"\"\"\n",
        "\n",
        "#AO_SYSTEM_PROMPT = \"\"\"\n",
        "#You are an expert document analysis agent specialized in extracting skills, technologies, frameworks, and other relevant information from documents, focusing on Call for Tenders (Appel d'Offres).\n",
        "#\n",
        "#Your goal is to provide accurate, reliable analysis based *only* on the provided document.\n",
        "#\n",
        "#1. Understand the user's query clearly.\n",
        "#2. Strategically search relevant sections of the document using your knowledge base.\n",
        "#3. Synthesize information from multiple parts if needed.\n",
        "#4. Provide well-structured, concise answers.\n",
        "#\n",
        "#Focus your search on relevant sections mentioned (like 'section 1.2.3' or 'section 4.2' or 'header page') if specified in the query.\n",
        "#\n",
        "#Your responses should:\n",
        "#- Be formatted as bullet points.\n",
        "#- Include confidence percentages for each point (e.g., 'Python - 3/4').\n",
        "#- Be concise but informative.\n",
        "#- Only include information actually found in the document.\n",
        "#- Never invent or assume information not explicitly stated.\n",
        "#\n",
        "#Always maintain a neutral, analytical tone.\n",
        "#If the knowledge base is empty or the document hasn't been ingested, inform the user they need to ingest a PDF first using the 'ingest_pdf_document' tool with the file path.\n",
        "#\"\"\"\n",
        "#\n",
        "#CV_SYSTEM_PROMPT = \"\"\"\n",
        "#You are an analytic system specialized in analyzing CV (Curriculum Vitae) documents.\n",
        "#\n",
        "#Your task is to analyse the CV and answer the question or task given to you.\n",
        "#\n",
        "#You have to avoid inventing new skills and only mention those in the file.\n",
        "#You have to list the various skills mentioned in the file and evaluate the level of knowledge for such skills.\n",
        "#Convert experiences into skills and evaluate the level of knowledge on a scale of 1 to 4 (1=Basic, 2=Working, 3=Advanced, 4=Expert).\n",
        "#\n",
        "#To answer, first analyse the query, then use the knowledge base to gather relevant data, create a temporary answer, review it, and correct yourself before answering.\n",
        "#\n",
        "#Your responses MUST:\n",
        "#- Be formatted as a bullet point list.\n",
        "#- Stay neutral, factual, and based *only* on the document.\n",
        "#- Indicate the reliability/confidence for each skill as a percentage.\n",
        "#- Be short: a few words or one sentence per skill.\n",
        "#- Use the format: '- Skill Name - Level/4 - Confidence%' (e.g., '- Python - 3/4 ').\n",
        "#\n",
        "#If the knowledge base is empty or the document hasn't been ingested, inform the user they need to ingest a PDF first using the 'ingest_pdf_document' tool with the file path.\n",
        "#\"\"\"\n",
        "#\n",
        "#MATCHER_SYSTEM_PROMPT = \"\"\"[INST]\n",
        "#            # CONTEXT #\n",
        "#            You are a analytic system made for the very purpose of exploiting the data in files.\n",
        "#            You're very efficient to do your task : 20 years of works to analyse, scan and use data contained in files.\n",
        "#\n",
        "#            # OBJECTIVE #\n",
        "#            Your task is to read the files and compare the offer and CV : list the skills the CV mentionned that are required in the offer.\n",
        "#            Your task also include listing the skills required by the offer but missing in the CV.\n",
        "#            You MUST avoid inventing new skills, only use those in the file.\n",
        "#\n",
        "#            # CHAIN OF THOUGH #\n",
        "#            To answer, you first analyse the mission and list the required skills,\n",
        "#            then you read the CV to list the skills mentionned inside.\n",
        "#            After the list of skills from mission and CV are made : you compare the skills in the CV's skill list and mission's skill list to create an temporary answer.\n",
        "#            Make sure the skills are in the correct list :\n",
        "#            - if missing in the CV, it's a required skill missing.\n",
        "#            - if missing in the offer, it's a skill unrequired.\n",
        "#            - if present in both file, it's a matching skill.\n",
        "#            Finally you take the role of a human and read again your temporary answer and correct yourself before answering.\n",
        "#\n",
        "#            # RETURN FORMAT #\n",
        "#            You MUST make three list :\n",
        "#            - the missing skills in the CV but needed by the offer\n",
        "#            - the skills present in both the offer and the CV\n",
        "#            - the skills present in the CV but not needed by the offer\n",
        "#            DON'T make an opinion in your answer.\n",
        "#            You MUST indicate the fiability of your answer for each point in form of percentage of trust.\n",
        "#            You MUST not mistake skills from the CV and from the Mission content.\n",
        "#            [/INST]\n",
        "#\"\"\"\n",
        "\n",
        "#AO_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en analyse d'appels d'offres (AO).\n",
        "#\n",
        "#Votre mission est d'extraire TOUTES les compétences techniques, soft skills, certifications et expériences explicitement mentionnées ou sous-entendues dans le document fourni.\n",
        "#\n",
        "#Procédez ainsi :\n",
        "#\n",
        "#1. Lisez attentivement tout le contenu donné.\n",
        "#2. Relevez toutes les mentions de compétences, technologies, frameworks, outils, certifications, et expériences professionnelles exigées.\n",
        "#3. Ne laissez rien de côté, même les éléments brièvement mentionnés ou implicites.\n",
        "#\n",
        "#Classez clairement ces éléments comme suit, sous forme de bullet points précis :\n",
        "#\n",
        "#### Compétences techniques\n",
        "#- [Compétence] (Critique/Important/Souhaitable) : [description exacte du texte source]\n",
        "#\n",
        "#### Soft skills\n",
        "#- [Compétence] (Critique/Important/Souhaitable) : [description exacte du texte source]\n",
        "#\n",
        "#### Certifications\n",
        "#- [Certification] (Critique/Important/Souhaitable) : [description exacte du texte source]\n",
        "#\n",
        "#### Exigences d'expérience\n",
        "#- [Expérience exigée] (Critique/Important/Souhaitable) : [description exacte du texte source]\n",
        "#\n",
        "#Ne manquez aucune compétence. Soyez exhaustif, précis, et ne mentionnez rien qui ne figure explicitement ou implicitement dans le document.\n",
        "#\"\"\"\n",
        "#\n",
        "#CV_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en analyse de CV.\n",
        "#\n",
        "#Votre tâche est d'extraire TOUTES les compétences techniques, soft skills, certifications, et expériences professionnelles explicitement mentionnées ou implicites dans le CV.\n",
        "#\n",
        "#Pour chaque compétence, indiquez précisément :\n",
        "#\n",
        "#- Niveau d’expertise (de 1 à 4) :\n",
        "#  - 1 = Basique\n",
        "#  - 2 = Intermédiaire\n",
        "#  - 3 = Avancé\n",
        "#  - 4 = Expert\n",
        "#- Pourcentage de confiance (%) de votre évaluation.\n",
        "#- Une courte justification basée exclusivement sur le CV.\n",
        "#\n",
        "#Présentez votre analyse comme suit :\n",
        "#\n",
        "#### Compétences techniques\n",
        "#- [Compétence] – [Niveau]/4 – [Confiance]% : [Justification précise tirée du CV]\n",
        "#\n",
        "#### Soft skills\n",
        "#- [Compétence] – [Niveau]/4 – [Confiance]% : [Justification précise tirée du CV]\n",
        "#\n",
        "#### Certifications\n",
        "#- [Certification] – [Année si disponible]\n",
        "#\n",
        "#### Expériences clés\n",
        "#- [Poste ou expérience] – [Durée] : [Compétences démontrées précisément selon le CV]\n",
        "#\n",
        "#Ne manquez aucune compétence. Soyez exhaustif, précis, et n'inventez rien qui ne figure explicitement ou implicitement dans le CV.\n",
        "#\"\"\"\n",
        "#\n",
        "#MATCHER_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un expert en comparaison et matching entre compétences d’un Appel d’Offres (AO) et celles présentes dans un CV.\n",
        "#\n",
        "#Votre tâche est de produire une analyse extrêmement rigoureuse, claire et complète, en suivant précisément ces étapes :\n",
        "#\n",
        "#1. Lisez minutieusement la liste des compétences extraites de l'AO.\n",
        "#2. Lisez minutieusement la liste des compétences extraites du CV.\n",
        "#3. Comparez chaque compétence requise par l’AO avec celles présentes dans le CV, en prenant en compte explicitement :\n",
        "#   - Les compétences techniques (technologies, outils, langages, etc.)\n",
        "#   - Les soft skills (compétences comportementales)\n",
        "#   - Les certifications\n",
        "#   - Les expériences spécifiques exigées par l’AO\n",
        "#4. N’omettez aucune compétence mentionnée dans l’AO, même brièvement.\n",
        "#\n",
        "#Présentez précisément votre analyse sous ce format structuré :\n",
        "#\n",
        "### Analyse de correspondance AO–CV\n",
        "#\n",
        "#### Score global d'adéquation\n",
        "#- [Pourcentage global]% (fiabilité de l'analyse : [confiance]%)\n",
        "#\n",
        "#### ✅ Compétences présentes dans le CV et requises par l’AO\n",
        "#- [Compétence exacte] (Importance AO : Critique/Important/Souhaitable | Niveau CV : 1 à 4) – confiance : [confiance]%\n",
        "#  - Justification précise tirée des deux documents.\n",
        "#\n",
        "#### ❌ Compétences requises par l’AO absentes du CV\n",
        "#- [Compétence exacte] (Importance AO : Critique/Important/Souhaitable) – confiance : [confiance]%\n",
        "#  - Impact potentiel sur la candidature.\n",
        "#  - Suggestion concrète pour combler ce manque.\n",
        "#\n",
        "#### ⚠️ Compétences présentes dans le CV mais non explicitement requises par l’AO\n",
        "#- [Compétence exacte] (Niveau CV : 1 à 4) – confiance : [confiance]%\n",
        "#  - Valeur ajoutée potentielle pour la candidature.\n",
        "#\n",
        "#### 📌 Synthèse et recommandations finales\n",
        "#- Analyse concise et factuelle de l’adéquation globale.\n",
        "#- Recommandations précises pour renforcer la candidature.\n",
        "#\n",
        "#Soyez rigoureux, précis, exhaustif, et ne mentionnez jamais des compétences non explicitement présentes dans les deux documents analysés.\n",
        "#\"\"\"\n",
        "\n",
        "#AO_SYSTEM_PROMPT = \"\"\"\n",
        "#À partir du texte ci-dessous (contexte), liste EXHAUSTIVEMENT et UNIQUEMENT sous forme de liste à puces, toutes les compétences techniques, soft skills, certifications et expériences mentionnées. Ne rajoute aucune phrase supplémentaire.\n",
        "#\n",
        "#Réponds précisément sous ce format uniquement :\n",
        "#\n",
        "#### Compétences techniques\n",
        "#- compétence 1\n",
        "#- compétence 2\n",
        "#\n",
        "#### Soft skills\n",
        "#- compétence 1\n",
        "#- compétence 2\n",
        "#\n",
        "#### Certifications\n",
        "#- certification 1\n",
        "#- certification 2\n",
        "#\n",
        "#### Exigences d'expérience\n",
        "#- expérience 1\n",
        "#- expérience 2\n",
        "#\n",
        "#Voici le contexte à analyser précisément :\n",
        "#\"\"\"\n",
        "#\n",
        "#CV_SYSTEM_PROMPT = \"\"\"\n",
        "#À partir du contexte ci-dessous (CV), liste EXHAUSTIVEMENT et UNIQUEMENT sous forme de liste à puces toutes les compétences techniques, soft skills, certifications et expériences clés mentionnées explicitement ou implicitement.\n",
        "#\n",
        "#Pour chaque compétence, indique uniquement le niveau d'expertise de 1 à 4 et le pourcentage de confiance.\n",
        "#\n",
        "#Format précis attendu :\n",
        "#\n",
        "#### Compétences techniques\n",
        "#- compétence 1 - Niveau X/4 - Confiance X%\n",
        "#- compétence 2 - Niveau X/4 - Confiance X%\n",
        "#\n",
        "#### Soft skills\n",
        "#- compétence 1 - Niveau X/4 - Confiance X%\n",
        "#- compétence 2 - Niveau X/4 - Confiance X%\n",
        "#\n",
        "#### Certifications\n",
        "#- certification 1 - Année (si disponible)\n",
        "#- certification 2 - Année (si disponible)\n",
        "#\n",
        "#### Expériences clés\n",
        "#- expérience 1 - Durée\n",
        "#- expérience 2 - Durée\n",
        "#\n",
        "#Voici le contexte à analyser précisément :\n",
        "#\"\"\"\n",
        "\n",
        "#MATCHER_SYSTEM_PROMPT = \"\"\"\n",
        "#Voici les compétences extraites de l’AO et celles extraites du CV.\n",
        "#\n",
        "#Ta mission est uniquement de comparer rigoureusement ces deux listes :\n",
        "#\n",
        "#1. Liste les compétences présentes à la fois dans l’AO et dans le CV.\n",
        "#2. Liste les compétences exigées par l’AO mais absentes du CV.\n",
        "#3. Liste les compétences présentes dans le CV mais absentes de l’AO.\n",
        "#\n",
        "#Réponds précisément en respectant strictement ce format :\n",
        "#\n",
        "#### ✅ Présentes dans AO et CV\n",
        "#- compétence 1\n",
        "#- compétence 2\n",
        "#\n",
        "#### ❌ Présentes dans AO mais absentes du CV\n",
        "#- compétence 1\n",
        "#- compétence 2\n",
        "#\n",
        "#### ⚠️ Présentes dans CV mais absentes de l'AO\n",
        "#- compétence 1\n",
        "#- compétence 2\n",
        "#\n",
        "#Voici précisément les compétences à analyser :\n",
        "#\n",
        "#AO :\n",
        "#[Liste des compétences extraites AO]\n",
        "#\n",
        "#CV :\n",
        "#[Liste des compétences extraites CV]\n",
        "#\"\"\"\n",
        "#\n",
        "#AO_SYSTEM_PROMPT = \"\"\"\n",
        "#You are an expert document analysis agent specialized in extracting skills, programming language, technologies, frameworks, and other relevant information from documents, focusing on Call for Tenders (Appel d'Offres).\n",
        "#\n",
        "#Your goal is to provide accurate, reliable analysis based *only* on the provided document.\n",
        "#\n",
        "#1. Understand the user's query clearly.\n",
        "#2. Strategically search relevant sections of the document using your knowledge base.\n",
        "#3. Synthesize information from multiple parts if needed.\n",
        "#4. Provide well-structured, concise answers.\n",
        "#\n",
        "#Focus your search on relevant sections mentioned (like 'section 1.2.3' or 'section 4.2' or 'header page') if specified in the query.\n",
        "#\n",
        "#Your responses should:\n",
        "#- Be formatted as bullet points.\n",
        "#- Include confidence percentages for each point (e.g., 'Python - 3/4').\n",
        "#- Be concise but informative.\n",
        "#- Only include information actually found in the document.\n",
        "#- Never invent or assume information not explicitly stated.\n",
        "#\n",
        "#Always maintain a neutral, analytical tone.\n",
        "#If the knowledge base is empty or the document hasn't been ingested, inform the user they need to ingest a PDF first using the 'ingest_pdf_document' tool with the file path.\n",
        "#\"\"\"\n",
        "\n",
        "#CV_SYSTEM_PROMPT = \"\"\"\n",
        "#You are an analytic system specialized in analyzing CV (Curriculum Vitae) documents.\n",
        "#\n",
        "#Your task is to analyse the CV and answer the question or task given to you.\n",
        "#\n",
        "#You have to avoid inventing new skills and only mention those in the file.\n",
        "#You have to list the various skills mentioned in the file and evaluate the level of knowledge for such skills.\n",
        "#Convert experiences into skills and evaluate the level of knowledge on a scale of 1 to 4 (1=Basic, 2=Working, 3=Advanced, 4=Expert).\n",
        "#\n",
        "#To answer, first analyse the query, then use the knowledge base to gather relevant data, create a temporary answer, review it, and correct yourself before answering.\n",
        "#\n",
        "#Your responses MUST:\n",
        "#- Be formatted as a bullet point list.\n",
        "#- Stay neutral, factual, and based *only* on the document.\n",
        "#- Indicate the reliability/confidence for each skill as a percentage.\n",
        "#- Be short: a few words or one sentence per skill.\n",
        "#- Use the format: '- Skill Name - Level/4 - Confidence%' (e.g., '- Python - 3/4 ').\n",
        "#\n",
        "#If the knowledge base is empty or the document hasn't been ingested, inform the user they need to ingest a PDF first using the 'ingest_pdf_document' tool with the file path.\n",
        "#\"\"\"\n",
        "\n",
        "CV_SYSTEM_PROMPT = \"\"\"\n",
        "You are an expert HR talent-screener and technical recruiter.\n",
        "Your mission is to extract every relevant skill, technology, programming language,\n",
        "soft skill, certification and key experience from résumés (CVs).\n",
        "For each item you must:\n",
        "  • assign a mastery level from 1 (basic) to 4 (expert/project owner);\n",
        "  • give a confidence percentage (0–100 %);\n",
        "  • provide a short justification quoted or paraphrased from the CV (10-25 words).\n",
        "Group the results into the following **four sections**, each as a separate Markdown\n",
        "table:\n",
        "  1. Compétences techniques & outils\n",
        "  2. Soft skills\n",
        "  3. Certifications\n",
        "  4. Expériences clés (projets)\n",
        "Use French for headings and justifications, but keep API/library names in English.\n",
        "Never invent skills that are not clearly implied by the CV.\n",
        "Format example for each table row:\n",
        "| Python | 4 | 95 % | « Développé un assistant LLM en Python » |\n",
        "Keep tables compact (max 4 columns). No extra commentary outside the tables.\n",
        "\"\"\"\n",
        "\n",
        "#AO_SYSTEM_PROMPT = \"\"\"\n",
        "#Vous êtes un analyste expert en marchés publics et en gestion d’appels d’offres.\n",
        "#Votre tâche : lire un cahier des charges (français) et livrer un compte-rendu\n",
        "#structuré en **10 sections** :\n",
        "#\n",
        "#1. Métadonnées de l’appel d’offres\n",
        "#   - Présentez-les dans un tableau Markdown (champs : Titre, Référence,\n",
        "#     Pouvoir adjudicateur, Date de publication, Date limite de remise,\n",
        "#     Contact, Budget indicatif, Type de marché).\n",
        "#\n",
        "#2. Objectifs & périmètre du projet (bullet points).\n",
        "#\n",
        "#3. Exigences fonctionnelles ET techniques (bullets groupés par domaine).\n",
        "#\n",
        "#4. Livrables attendus.\n",
        "#\n",
        "#5. Planning & jalons (dates, durées, pénalités retard).\n",
        "#\n",
        "#6. Modalités de soumission & pièces à fournir.\n",
        "#\n",
        "#7. Critères d’évaluation (pondérations si disponibles).\n",
        "#\n",
        "#8. Budget, modalités de paiement, garanties financières.\n",
        "#\n",
        "#9. Clauses juridiques & administratives majeures\n",
        "#   (propriété intellectuelle, responsabilité, assurance, résiliation).\n",
        "#\n",
        "#10. Questions ouvertes / points de vigilance pour le soumissionnaire.\n",
        "#\n",
        "#**Règles de forme** :\n",
        "#• Français ; ne jamais traduire les citations.\n",
        "#• Chaque section commence par un titre Markdown `##`.\n",
        "#• Citez ou paraphrasez brièvement (10-25 mots) les passages\n",
        "#  sources entre guillemets français « … ».\n",
        "#• Mentionnez le **numéro de page** si celui-ci est indiqué dans le texte.\n",
        "#• Aucune digression en dehors des 10 sections.\n",
        "#\"\"\"\n",
        "#\n",
        "AO_SYSTEM_PROMPT = \"\"\"\n",
        "Tu es un consultant senior en Data & IA spécialisé dans l’analyse d’appels d’offres.\n",
        "Ta mission : extraire et structurer les informations de compétences contenues dans un AO.\n",
        "\n",
        "Règles de sortie :\n",
        "1. Distingue 5 catégories :\n",
        "   • Compétences techniques / outils\n",
        "   • Langages de programmation\n",
        "   • Soft-skills\n",
        "   • Certifications / normes / réglementations\n",
        "   • Expériences clés\n",
        "2. Pour **chaque** compétence trouvée :\n",
        "   • « Niveau » (1 à 4 : 1 = Connaissances, 2 = Maîtrise opérationnelle, 3 = Avancé, 4 = Expertise)\n",
        "   • « Confiance » (%) sur le fait que l’AO l’exige réellement\n",
        "   • « Justification » : extrait littéral ou résumé très court (< 20 mots) provenant de l’AO\n",
        "3. Formate la réponse en **tableau Markdown** avec les colonnes :\n",
        "   | Compétence | Catégorie | Niveau | Confiance | Justification |\n",
        "4. Range les lignes par catégorie puis par importance (Niveau 4 → 1, puis confiance décroissante).\n",
        "5. N’invente rien ; si l’info n’apparaît pas, ne l’ajoute pas.\n",
        "6. Limite la sortie à 60 lignes max.\n",
        "Réponds toujours en français.\n",
        "\"\"\"\n",
        "\n",
        "CV_SYSTEM_PROMPT = \"\"\"\n",
        "Vous êtes un expert en analyse de CV.\n",
        "\n",
        "Votre tâche est d'extraire TOUTES les compétences techniques, soft skills, certifications, et expériences professionnelles explicitement mentionnées ou implicites dans le CV.\n",
        "\n",
        "Pour chaque compétence, indiquez précisément :\n",
        "\n",
        "- Niveau d'expertise (de 1 à 4) :\n",
        "  - 1 = Basique\n",
        "  - 2 = Intermédiaire\n",
        "  - 3 = Avancé\n",
        "  - 4 = Expert\n",
        "- Pourcentage de confiance (%) de votre évaluation.\n",
        "- Une courte justification basée exclusivement sur le CV.\n",
        "\n",
        "Présentez votre analyse comme suit :\n",
        "\n",
        "## Compétences techniques\n",
        "- [Compétence] – [Niveau]/4 – [Confiance]% : [Justification précise tirée du CV]\n",
        "\n",
        "## Soft skills\n",
        "- [Compétence] – [Niveau]/4 – [Confiance]% : [Justification précise tirée du CV]\n",
        "\n",
        "## Certifications\n",
        "- [Certification] – [Année si disponible]\n",
        "\n",
        "## Expériences clés\n",
        "- [Poste ou expérience] – [Durée] : [Compétences démontrées précisément selon le CV]\n",
        "\n",
        "Ne manquez aucune compétence. Soyez exhaustif, précis, et n'inventez rien qui ne figure explicitement ou implicitement dans le CV.\n",
        "\"\"\"\n",
        "\n",
        "MATCHER_SYSTEM_PROMPT = \"\"\"\n",
        "Vous êtes un expert en comparaison et matching entre compétences d'un Appel d'Offres (AO) et celles présentes dans un CV.\n",
        "\n",
        "Votre tâche est de produire une analyse extrêmement rigoureuse, claire et complète, en suivant précisément ces étapes :\n",
        "\n",
        "1. Lisez minutieusement la liste des compétences extraites de l'AO.\n",
        "2. Lisez minutieusement la liste des compétences extraites du CV.\n",
        "3. Comparez chaque compétence requise par l'AO avec celles présentes dans le CV, en prenant en compte explicitement :\n",
        "   - Les compétences techniques (technologies, outils, langages, etc.)\n",
        "   - Les soft skills (compétences comportementales)\n",
        "   - Les certifications\n",
        "   - Les expériences spécifiques exigées par l'AO\n",
        "4. N'omettez aucune compétence mentionnée dans l'AO, même brièvement.\n",
        "\n",
        "Présentez précisément votre analyse sous ce format structuré :\n",
        "\n",
        "## Analyse de correspondance AO–CV\n",
        "\n",
        "### Score global d'adéquation\n",
        "- [Pourcentage global]% (fiabilité de l'analyse : [confiance]%)\n",
        "\n",
        "### ✅ Compétences présentes dans le CV et requises par l'AO\n",
        "- [Compétence exacte] (Importance AO : Critique/Important/Souhaitable | Niveau CV : 1 à 4) – confiance : [confiance]%\n",
        "  - Justification précise tirée des deux documents.\n",
        "\n",
        "### ❌ Compétences requises par l'AO absentes du CV\n",
        "- [Compétence exacte] (Importance AO : Critique/Important/Souhaitable) – confiance : [confiance]%\n",
        "  - Impact potentiel sur la candidature.\n",
        "  - Suggestion concrète pour combler ce manque.\n",
        "\n",
        "### ⚠️ Compétences présentes dans le CV mais non explicitement requises par l'AO\n",
        "- [Compétence exacte] (Niveau CV : 1 à 4) – confiance : [confiance]%\n",
        "  - Valeur ajoutée potentielle pour la candidature.\n",
        "\n",
        "### 📌 Synthèse et recommandations finales\n",
        "- Analyse concise et factuelle de l'adéquation globale.\n",
        "- Recommandations précises pour renforcer la candidature.\n",
        "\n",
        "Soyez rigoureux, précis, exhaustif, et ne mentionnez jamais des compétences non explicitement présentes dans les deux documents analysés.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# --- Fonctions de retrieval optimisées ---\n",
        "def vectorstore_retrieval(state: AgentState, vector_store: Chroma, collection_name: str, s: float = 0.15, k: int = 100) -> AgentState:\n",
        "    \"\"\"\n",
        "    Récupération de documents améliorée avec meilleure gestion d'erreurs et récupération.\n",
        "    Optimisée pour la performance et la robustesse.\n",
        "    \"\"\"\n",
        "    global vector_store_AO, vector_store_CV\n",
        "\n",
        "    start_time = time.time()\n",
        "    collection_id = hashlib.md5(collection_name.encode()).hexdigest()\n",
        "    logger.info(f\"Début de la recherche dans {collection_name} (ID: {collection_id})\")\n",
        "\n",
        "    # Obtenir la requête utilisateur\n",
        "    user_query = state.get(\"messages\", [{}])[-1].get(\"content\", \"\")\n",
        "    if not user_query or len(user_query.strip()) < 3:\n",
        "        state[\"context\"] = \"Requête trop courte ou vide. Veuillez fournir une question plus détaillée.\"\n",
        "        return state\n",
        "\n",
        "    logger.info(f\"Requête: {user_query[:100]}...\")\n",
        "\n",
        "    try:\n",
        "        # Vérifier si la collection existe et contient des documents\n",
        "        #try:\n",
        "        #    count = len(vector_store.get())\n",
        "        #    logger.info(f\"Collection '{collection_name}' (ID: {collection_id}) existe avec {count} documents\")\n",
        "        #\n",
        "        #    if count == 0:\n",
        "        #        # Recréer la collection si elle est vide\n",
        "        #        logger.warning(f\"Collection '{collection_name}' vide, tentative de recréation...\")\n",
        "        #        if collection_name == \"AO_documents\":\n",
        "        #            vector_store_AO = create_or_get_collection(collection_name)\n",
        "        #            vector_store = vector_store_AO\n",
        "        #        else:\n",
        "        #            vector_store_CV = create_or_get_collection(collection_name)\n",
        "        #            vector_store = vector_store_CV\n",
        "        #\n",
        "        #        # Vérifier à nouveau\n",
        "        #        count = len(vector_store.get())\n",
        "        #        if count == 0:\n",
        "        #            state[\"context\"] = (\n",
        "        #                \"Aucun document dans la collection. \"\n",
        "        #                \"Veuillez d'abord ingérer un document.\"\n",
        "        #            )\n",
        "        #            return state\n",
        "        #except Exception as e:\n",
        "        #    logger.warning(f\"Erreur lors de la vérification de la collection '{collection_name}': {e}\")\n",
        "        #\n",
        "        #    # Recréer la collection\n",
        "        #    if collection_name == \"AO_documents\":\n",
        "        #        vector_store_AO = create_or_get_collection(collection_name)\n",
        "        #        vector_store = vector_store_AO\n",
        "        #    else:\n",
        "        #        vector_store_CV = create_or_get_collection(collection_name)\n",
        "        #        vector_store = vector_store_CV\n",
        "        #\n",
        "        #    # Vérifier à nouveau\n",
        "        #    try:\n",
        "        #        count = len(vector_store.get())\n",
        "        #        if count == 0:\n",
        "        #            state[\"context\"] = (\n",
        "        #                \"Collection recréée mais vide. \"\n",
        "        #                \"Veuillez ingérer un document.\"\n",
        "        #            )\n",
        "        #            return state\n",
        "        #    except Exception as inner_e:\n",
        "        #        logger.error(f\"Échec de vérification après recréation: {inner_e}\")\n",
        "        #        state[\"context\"] = (\n",
        "        #            \"Erreur lors de l'initialisation de la base de connaissance. \"\n",
        "        #            \"Veuillez réessayer d'ingérer le document.\"\n",
        "        #        )\n",
        "        #        return state\n",
        "\n",
        "        if collection_name == \"AO_documents\":\n",
        "            vector_store_AO = create_or_get_collection(f\"AO_documents\")\n",
        "            vector_store = vector_store_AO\n",
        "        else:\n",
        "            vector_store_CV = create_or_get_collection(f\"CV_documents\")\n",
        "            vector_store = vector_store_CV\n",
        "\n",
        "        # Créer le retriever\n",
        "        if collection_name == \"AO_documents\":\n",
        "            #retriever = vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": s, \"k\" : 100})\n",
        "            retriever = vector_store.as_retriever(search_kwargs={\"k\" : 2}) #1200-400 33 12000-400 13 12000-100\n",
        "        else :\n",
        "            retriever = vector_store.as_retriever(search_kwargs={\"k\" : 40})\n",
        "        # Exécuter la recherche avec retry\n",
        "        docs = None\n",
        "        last_error = None\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"Tentative de recherche\")\n",
        "            docs = retriever.get_relevant_documents(user_query)\n",
        "            print(\"haha :\", len(docs))\n",
        "            logger.info(f\"Recherche réussie: {len(docs)} documents trouvés\")\n",
        "        except Exception as e:\n",
        "            last_error = e\n",
        "            logger.warning(f\"Tentative de recherche échouée: {e}\")\n",
        "\n",
        "        # Vérifier si la recherche a échoué après toutes les tentatives\n",
        "        if docs is None:\n",
        "            state[\"context\"] = f\"Erreur lors de la recherche après une tentatives: {last_error}\"\n",
        "            return state\n",
        "\n",
        "        # Traiter les résultats de recherche\n",
        "        if not docs:\n",
        "            state[\"context\"] = (\n",
        "                \"Aucune information pertinente trouvée. \"\n",
        "                \"Vérifiez que le document a bien été ingéré ou reformulez votre question.\"\n",
        "            )\n",
        "            return state\n",
        "\n",
        "        # Déduplication améliorée avec similarité de contenu\n",
        "        unique_docs = {}\n",
        "        for doc in docs:\n",
        "            # Utiliser un hash du contenu pour la déduplication\n",
        "            content = doc.page_content.strip()\n",
        "            h = hashlib.md5(content.encode()).hexdigest()\n",
        "\n",
        "            # Si le document est déjà présent, ne garder que le plus pertinent\n",
        "            # (supposé être celui qui apparaît en premier dans la liste)\n",
        "            if h not in unique_docs:\n",
        "                unique_docs[h] = doc\n",
        "\n",
        "        # Garder uniquement les résultats uniques les plus pertinents\n",
        "        filtered_docs = unique_docs.values()\n",
        "        print(len(filtered_docs))\n",
        "\n",
        "        # Formater le contexte avec des séparateurs clairs\n",
        "        context_parts = []\n",
        "        i = 0\n",
        "        for doc in filtered_docs:\n",
        "            i += 1\n",
        "            print(\"*******\")\n",
        "            print(doc)\n",
        "            context_parts.append(f\"--- Document {i+1} ---\\n{doc.page_content.strip()}\")\n",
        "\n",
        "        state[\"context\"] = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "        # Mesurer et logger le temps total\n",
        "        total_time = time.time() - start_time\n",
        "        logger.info(f\"Recherche terminée en {total_time:.2f}s: {len(filtered_docs)} documents uniques\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erreur lors de la récupération des documents: {e}\", exc_info=True)\n",
        "        state[\"context\"] = f\"Erreur interne lors de la récupération: {e}\"\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def vectorstore_retrieval_AO(state: AgentState) -> AgentState:\n",
        "    \"\"\"Récupération spécifique pour les documents AO.\"\"\"\n",
        "    return vectorstore_retrieval(state, vector_store_AO, \"AO_documents\", s=0.01)\n",
        "\n",
        "\n",
        "def vectorstore_retrieval_CV(state: AgentState) -> AgentState:\n",
        "    \"\"\"Récupération spécifique pour les documents CV avec plus de contexte.\"\"\"\n",
        "    return vectorstore_retrieval(state, vector_store_CV, \"CV_documents\", k=50)\n",
        "\n",
        "\n",
        "# --- Agent Executor optimisé ---\n",
        "def create_agent_executor(system_prompt: str) -> Callable:\n",
        "    \"\"\"\n",
        "    Crée une fonction d'exécution d'agent avec le prompt système spécifié.\n",
        "    Version optimisée avec gestion des erreurs et retries.\n",
        "    \"\"\"\n",
        "    def agent_executor(state: AgentState) -> AgentState:\n",
        "        start_time = time.time()\n",
        "        logger.info(\"Démarrage de l'exécution de l'agent\")\n",
        "\n",
        "        # Obtenir le contexte et la requête utilisateur\n",
        "        context = state.get(\"context\", \"\")\n",
        "        messages = state[\"messages\"]\n",
        "        user_query = messages[-1][\"content\"]\n",
        "\n",
        "        # Vérifier si le contexte est vide ou contient un message d'erreur\n",
        "        if not context or context.startswith(\"Erreur:\") or context.startswith(\"Aucune information\"):\n",
        "            error_msg = \"Aucun document n'a été correctement traité. Veuillez vous assurer que le document a été ingéré avec succès avant d'extraire les compétences.\"\n",
        "            messages.append({\"role\": \"assistant\", \"content\": error_msg})\n",
        "            state[\"messages\"] = messages\n",
        "            logger.warning(\"Exécution annulée: contexte invalide ou manquant\")\n",
        "            return state\n",
        "\n",
        "        # Créer le prompt avec un format optimisé\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{query}\" + \"\"\"\n",
        "            ####\n",
        "            {context}\n",
        "            ####\"\"\")\n",
        "            ])\n",
        "\n",
        "        # Formater le prompt avec le contexte et la requête\n",
        "        formatted_prompt = prompt.format(context=context, query=user_query)\n",
        "\n",
        "        # Obtenir le LLM avec des paramètres adaptés à la tâche\n",
        "        # - Température plus basse pour l'extraction factuelle\n",
        "        llm = get_llm(temperature=0.1, top_p=1.0, top_k=40)\n",
        "\n",
        "        last_error = None\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"Invocation du LLM ...\")\n",
        "            response = llm.invoke(formatted_prompt)\n",
        "\n",
        "            # Vérification de cohérence basique\n",
        "            content = response.content\n",
        "            if not content or len(content) < 50:\n",
        "                raise ValueError(\"Réponse trop courte ou vide\")\n",
        "\n",
        "            # Vérification supplémentaire pour les formats attendus\n",
        "            if \"## Compétences techniques\" not in content:\n",
        "                logger.warning(\"Format de réponse potentiellement incorrect\")\n",
        "                # Continuer malgré l'avertissement\n",
        "\n",
        "            # Ajouter le message assistant\n",
        "            messages.append({\"role\": \"assistant\", \"content\": content})\n",
        "            state[\"messages\"] = messages\n",
        "\n",
        "            # Si c'est une extraction de compétences AO ou CV, stocker dans l'état\n",
        "            if \"Liste des compétences\" in user_query.lower() and \"AO\" in user_query:\n",
        "                state[\"ao_skills\"] = content\n",
        "                logger.info(\"Compétences AO extraites et stockées dans l'état\")\n",
        "            elif \"Liste des compétences\" in user_query.lower() and \"CV\" in user_query:\n",
        "                state[\"cv_skills\"] = content\n",
        "                logger.info(\"Compétences CV extraites et stockées dans l'état\")\n",
        "\n",
        "            # Mesurer et logger le temps total\n",
        "            total_time = time.time() - start_time\n",
        "            logger.info(f\"LLM invoqué avec succès en {total_time:.2f}s\")\n",
        "            return state\n",
        "\n",
        "        except Exception as e:\n",
        "            last_error = e\n",
        "            logger.warning(f\"Erreur lors de l'invocation du LLM : {e}\")\n",
        "\n",
        "            error_msg = f\"Désolé, je n'ai pas pu générer une réponse valide. Erreur: {str(e)}\"\n",
        "            messages.append({\"role\": \"assistant\", \"content\": error_msg})\n",
        "            state[\"messages\"] = messages\n",
        "            logger.error(f\"Échec de l'exécution de l'agent\")\n",
        "            return state\n",
        "\n",
        "    return agent_executor\n",
        "\n",
        "# --- Fonction de comparaison améliorée ---\n",
        "def compare_ao_cv(ao_skills: str, cv_skills: str) -> str:\n",
        "    \"\"\"\n",
        "    Compare les compétences extraites de l'AO et du CV.\n",
        "    Version améliorée avec normalisation des compétences et détection des relations.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    logger.info(\"Démarrage de la comparaison AO-CV\")\n",
        "\n",
        "    # Validation des entrées\n",
        "    if not ao_skills or len(ao_skills) < 100:\n",
        "        logger.warning(\"Compétences AO manquantes ou insuffisantes\")\n",
        "        return \"Erreur: Les compétences de l'AO sont manquantes ou insuffisantes. Veuillez d'abord extraire les compétences de l'AO.\"\n",
        "\n",
        "    if not cv_skills or len(cv_skills) < 100:\n",
        "        logger.warning(\"Compétences CV manquantes ou insuffisantes\")\n",
        "        return \"Erreur: Les compétences du CV sont manquantes ou insuffisantes. Veuillez d'abord extraire les compétences du CV.\"\n",
        "\n",
        "    # Obtenir le LLM avec des paramètres adaptés à la tâche de matching\n",
        "    # - Température plus élevée pour permettre plus de créativité dans l'analyse\n",
        "    llm = get_llm(temperature=0.7, top_p=0.9, top_k=40)\n",
        "\n",
        "    # Créer les messages pour le LLM avec un format optimisé\n",
        "    messages = [\n",
        "        SystemMessage(content=MATCHER_SYSTEM_PROMPT),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "Veuillez comparer les compétences requises dans l'Appel d'Offres (AO) avec celles présentes dans le CV.\n",
        "\n",
        "# Compétences requises dans l'AO:\n",
        "{ao_skills}\n",
        "\n",
        "# Compétences présentes dans le CV:\n",
        "{cv_skills}\n",
        "\n",
        "Analysez la correspondance entre ces deux ensembles de compétences et fournissez une évaluation détaillée.\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    # Obtenir la réponse avec retry et backoff exponentiel\n",
        "    last_error = None\n",
        "\n",
        "    try:\n",
        "        logger.info(f\"Invocation du Matcher LLM ...\")\n",
        "        response = llm.invoke(messages)\n",
        "\n",
        "        # Vérification de cohérence basique\n",
        "        content = response.content\n",
        "        if not content or len(content) < 100:\n",
        "            raise ValueError(\"Réponse de comparaison trop courte ou vide\")\n",
        "\n",
        "        # Vérification supplémentaire pour les formats attendus\n",
        "        if \"Score global d'adéquation\" not in content:\n",
        "            logger.warning(\"Format de réponse de comparaison potentiellement incorrect\")\n",
        "            # Continuer malgré l'avertissement\n",
        "\n",
        "        # Mesurer et logger le temps total\n",
        "        total_time = time.time() - start_time\n",
        "        logger.info(f\"Comparaison AO-CV réussie en {total_time:.2f}s\")\n",
        "        return content\n",
        "\n",
        "    except Exception as e:\n",
        "        last_error = e\n",
        "        logger.warning(f\"Erreur lors de la comparaison AO-CV : {e}\")\n",
        "\n",
        "        logger.error(f\"Échec de la comparaison AO-CV \")\n",
        "        return f\"Erreur lors de la comparaison: {str(e)}\"\n",
        "\n",
        "# --- LangGraph Workflow optimisé ---\n",
        "def create_agent_graph_AO(agent_type: str):\n",
        "    \"\"\"\n",
        "    Crée un graphe d'agent pour l'analyse d'AO.\n",
        "    Version optimisée avec meilleure gestion d'état.\n",
        "    \"\"\"\n",
        "    # Créer un graphe d'état\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Ajouter les nœuds\n",
        "    workflow.add_node(\"retrieval\", vectorstore_retrieval_AO)\n",
        "    workflow.add_node(\"agent_executor\", create_agent_executor(AO_SYSTEM_PROMPT))\n",
        "\n",
        "    # Créer l'outil LangChain\n",
        "    pdf_tool = Tool(\n",
        "        name=\"ingest_pdf_document\",\n",
        "        func=ingest_pdf_document_AO,\n",
        "        description=\"Charge ou remplace le contenu d'un document PDF dans le vector store. Fournir le chemin absolu vers le PDF.\"\n",
        "    )\n",
        "\n",
        "    # Ajouter le nœud d'outils\n",
        "    tools_node = ToolNode([pdf_tool])\n",
        "    workflow.add_node(\"tools\", tools_node)\n",
        "\n",
        "    # Ajouter les arêtes\n",
        "    workflow.add_edge(\"retrieval\", \"agent_executor\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"agent_executor\",\n",
        "        lambda state: \"tools\" if \"ingest_pdf_document\" in state.get(\"messages\", [{}])[-1].get(\"content\", \"\").lower() else END\n",
        "    )\n",
        "    workflow.add_edge(\"tools\", \"agent_executor\")\n",
        "\n",
        "    # Définir le point d'entrée\n",
        "    workflow.set_entry_point(\"retrieval\")\n",
        "\n",
        "    # Compiler le graphe\n",
        "    return workflow.compile()\n",
        "\n",
        "def create_agent_graph_CV(agent_type: str):\n",
        "    \"\"\"\n",
        "    Crée un graphe d'agent pour l'analyse de CV.\n",
        "    Version optimisée avec meilleure gestion d'état.\n",
        "    \"\"\"\n",
        "    # Créer un graphe d'état\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Ajouter les nœuds\n",
        "    workflow.add_node(\"retrieval\", vectorstore_retrieval_CV)\n",
        "    workflow.add_node(\"agent_executor\", create_agent_executor(CV_SYSTEM_PROMPT))\n",
        "\n",
        "    # Créer l'outil LangChain\n",
        "    pdf_tool = Tool(\n",
        "        name=\"ingest_pdf_document\",\n",
        "        func=ingest_pdf_document_CV,\n",
        "        description=\"Charge ou remplace le contenu d'un document PDF dans le vector store. Fournir le chemin absolu vers le PDF.\"\n",
        "    )\n",
        "\n",
        "    # Ajouter le nœud d'outils\n",
        "    tools_node = ToolNode([pdf_tool])\n",
        "    workflow.add_node(\"tools\", tools_node)\n",
        "\n",
        "    # Ajouter les arêtes\n",
        "    workflow.add_edge(\"retrieval\", \"agent_executor\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"agent_executor\",\n",
        "        lambda state: \"tools\" if \"ingest_pdf_document\" in state.get(\"messages\", [{}])[-1].get(\"content\", \"\").lower() else END\n",
        "    )\n",
        "    workflow.add_edge(\"tools\", \"agent_executor\")\n",
        "\n",
        "    # Définir le point d'entrée\n",
        "    workflow.set_entry_point(\"retrieval\")\n",
        "\n",
        "    # Compiler le graphe\n",
        "    return workflow.compile()\n",
        "\n",
        "import chromadb\n",
        "\n",
        "def reset_vector_store(collection_name: str) -> Chroma:\n",
        "    \"\"\"\n",
        "    Supprime et recrée une collection Chroma vide.\n",
        "    \"\"\"\n",
        "    collection_id = hashlib.md5(collection_name.encode()).hexdigest()\n",
        "    chroma_client = chromadb.Client(settings=settings)\n",
        "\n",
        "\n",
        "    try:\n",
        "        chroma_client.delete_collection(name=collection_id)\n",
        "        logger.info(f\"Collection {collection_id} supprimée avec succès\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Impossible de supprimer la collection {collection_id} : {e}\")\n",
        "\n",
        "    # Recrée une collection vide\n",
        "    return Chroma(\n",
        "        collection_name=collection_id,\n",
        "        embedding_function=embeddings,\n",
        "        client_settings=settings\n",
        "    )\n",
        "\n",
        "# --- Streamlit UI ---\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"Matching AO-CV\",\n",
        "        page_icon=\"📄\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "\n",
        "    st.title(\"Matching AO-CV\")\n",
        "    st.markdown(\"\"\"\n",
        "    Cette application analyse les compétences requises dans un Appel d'Offres (AO)\n",
        "    et les compare avec celles présentes dans un CV pour évaluer l'adéquation.\n",
        "    \"\"\")\n",
        "\n",
        "    # Initialiser les états de session\n",
        "    if \"ao_graph\" not in st.session_state:\n",
        "        st.session_state.ao_graph = create_agent_graph_AO(\"AO\")\n",
        "    if \"cv_graph\" not in st.session_state:\n",
        "        st.session_state.cv_graph = create_agent_graph_CV(\"CV\")\n",
        "    if \"ao_skills\" not in st.session_state:\n",
        "        st.session_state.ao_skills = \"\"\n",
        "    if \"cv_skills\" not in st.session_state:\n",
        "        st.session_state.cv_skills = \"\"\n",
        "    if \"matching_result\" not in st.session_state:\n",
        "        st.session_state.matching_result = \"\"\n",
        "\n",
        "    # Layout en colonnes\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    # Colonne AO\n",
        "    with col1:\n",
        "        st.header(\"Appel d'Offres (AO)\")\n",
        "        ao_file = st.file_uploader(\"Télécharger un document AO (PDF)\", key=\"ao_upload\") #, type=[\"pdf\"]\n",
        "\n",
        "        if ao_file:\n",
        "            # Sauvegarder le fichier temporairement\n",
        "            ao_path = os.path.join(AGENT_STORAGE_DIR, \"ao_temp.mkd\")\n",
        "            with open(ao_path, \"wb\") as f:\n",
        "                f.write(ao_file.getvalue())\n",
        "                ao_file._file_urls\n",
        "\n",
        "            if st.button(\"Analyser l'AO\"):\n",
        "                with st.spinner(\"Analyse de l'AO en cours...\"):\n",
        "                    # Ingérer le document\n",
        "                    ingest_result = ingest_pdf_document_AO(ao_path)\n",
        "                    st.info(ingest_result)\n",
        "\n",
        "                    # Extraire les compétences\n",
        "                    if \"échoué\" not in ingest_result and \"Erreur\" not in ingest_result:\n",
        "                        result = st.session_state.ao_graph.invoke({\n",
        "                            \"messages\": [{\"role\": \"human\", \"content\": \"Liste des compétences requises dans cet AO\"}]\n",
        "                        })\n",
        "\n",
        "                        if result and \"messages\" in result and len(result[\"messages\"]) > 1:\n",
        "                            st.session_state.ao_skills = result[\"messages\"][-1][\"content\"]\n",
        "                            st.success(\"Extraction des compétences réussie!\")\n",
        "\n",
        "        # Afficher les compétences extraites\n",
        "        if st.session_state.ao_skills:\n",
        "            st.subheader(\"Compétences extraites\")\n",
        "            st.markdown(st.session_state.ao_skills)\n",
        "\n",
        "    # Colonne CV\n",
        "    with col2:\n",
        "        st.header(\"Curriculum Vitae (CV)\")\n",
        "        cv_file = st.file_uploader(\"Télécharger un CV (PDF)\", type=[\"pdf\"], key=\"cv_upload\")\n",
        "\n",
        "        if cv_file:\n",
        "            # Sauvegarder le fichier temporairement\n",
        "            cv_path = os.path.join(AGENT_STORAGE_DIR, \"cv_temp.pdf\")\n",
        "            with open(cv_path, \"wb\") as f:\n",
        "                f.write(cv_file.getvalue())\n",
        "\n",
        "            if st.button(\"Analyser le CV\"):\n",
        "                with st.spinner(\"Analyse du CV en cours...\"):\n",
        "                    # Ingérer le document\n",
        "                    ingest_result = ingest_pdf_document_CV(cv_path)\n",
        "                    st.info(ingest_result)\n",
        "\n",
        "                    # Extraire les compétences\n",
        "                    if \"échoué\" not in ingest_result and \"Erreur\" not in ingest_result:\n",
        "                        result = st.session_state.cv_graph.invoke({\n",
        "                            \"messages\": [{\"role\": \"human\", \"content\": \"Liste des compétences présentes dans ce CV\"}]\n",
        "                        })\n",
        "\n",
        "                        if result and \"messages\" in result and len(result[\"messages\"]) > 1:\n",
        "                            st.session_state.cv_skills = result[\"messages\"][-1][\"content\"]\n",
        "                            st.success(\"Extraction des compétences réussie!\")\n",
        "\n",
        "        # Afficher les compétences extraites\n",
        "        if st.session_state.cv_skills:\n",
        "            st.subheader(\"Compétences extraites\")\n",
        "            st.markdown(st.session_state.cv_skills)\n",
        "\n",
        "    # Section de matching\n",
        "    st.header(\"Analyse de correspondance\")\n",
        "\n",
        "    if st.session_state.ao_skills and st.session_state.cv_skills:\n",
        "        if st.button(\"Analyser la correspondance AO-CV\"):\n",
        "            with st.spinner(\"Analyse de correspondance en cours...\"):\n",
        "                matching_result = compare_ao_cv(st.session_state.ao_skills, st.session_state.cv_skills)\n",
        "                st.session_state.matching_result = matching_result\n",
        "\n",
        "    # Afficher le résultat du matching\n",
        "    if st.session_state.matching_result:\n",
        "        st.subheader(\"Résultat de l'analyse\")\n",
        "        st.markdown(st.session_state.matching_result)\n",
        "\n",
        "        # Extraire le score global\n",
        "        #try:\n",
        "        #    score_line = [line for line in st.session_state.matching_result.split(\"\\n\") if \"Score global d'adéquation\" in line][0]\n",
        "        #    score = int(score_line.split(\"%\")[0].split(\":\")[-1].strip())\n",
        "        #\n",
        "        #    # Afficher une jauge pour le score\n",
        "        #    st.subheader(\"Score d'adéquation\")\n",
        "        #    st.progress(score / 100)\n",
        "        #    if score >= 80:\n",
        "        #        st.success(f\"{score}% - Excellente correspondance\")\n",
        "        #    elif score >= 60:\n",
        "        #        st.info(f\"{score}% - Bonne correspondance\")\n",
        "        #    elif score >= 40:\n",
        "        #        st.warning(f\"{score}% - Correspondance moyenne\")\n",
        "        #    else:\n",
        "        #        st.error(f\"{score}% - Correspondance faible\")\n",
        "        #except:\n",
        "        #    st.warning(\"Impossible d'extraire le score d'adéquation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.title('Streamlit in Colab')\n",
        "st.write(\"Hello, Streamlit!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg_A9mgDOF6K",
        "outputId": "28b91adc-c5d1-42da-95ea-34aaeb2b4352"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNL1sPntLZSo",
        "outputId": "2ba8608c-3563-4bf2-b289-e7ee5a7bacfb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.190.155.112:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27mOZ9OZO9cH",
        "outputId": "53833b65-510c-4b5e-f24e-dedb650c5d60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Start the Streamlit app in the background\n",
        "os.system(\"streamlit run app.py &\")\n",
        "\n",
        "# Create a public URL for the Streamlit app\n",
        "public_url = ngrok.connect(8501)\n",
        "print('Streamlit app available at:', public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "xYyOGeNxOMu2",
        "outputId": "e6a38534-016e-440c-b0c8-3949e5cc1b22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-06-12T13:02:34+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-06-12T13:02:34+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-06-12T13:02:34+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-06-12T13:02:34+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3830272702>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create a public URL for the Streamlit app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Streamlit app available at:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    448\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fqP-KZpXPCS1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}